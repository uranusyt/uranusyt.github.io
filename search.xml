<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>群体结构分析三种常用方法 (上篇)</title>
      <link href="/2019/05/13/population-analysis1/"/>
      <url>/2019/05/13/population-analysis1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h5 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h5><p>在群体遗传学和进化生物学相关的项目中，群体结构分析是最常见也是最初步的分析内容，可以帮助我们确认样本分群是否符合预期以及检测离群样本。群体结构分析最常用的三种方法就是PCA、系统发生树和祖先成分堆叠图，下面我们将使用发表在Genome Rearch上的<a href="https://genome.cshlp.org/content/24/8/1308.long" target="_blank" rel="noopener">Gou et al,2014</a>中的数据（60只狗全基因组SNP）逐一讲解。</p><h2 id="一、-PCA分析"><a href="#一、-PCA分析" class="headerlink" title="一、 PCA分析"></a>一、 PCA分析</h2><h4 id="1-简单介绍PCA原理"><a href="#1-简单介绍PCA原理" class="headerlink" title="1. 简单介绍PCA原理"></a>1. 简单介绍PCA原理</h4><p>PCA (Principal Component Analysis) ，即主成分分析方法，是一种使用最广泛的数据降维算法，通过正交变换将一组数量庞大且可能存在相关性的变量转换为一组低维的线性不相关的变量。<br>对于一个全基因组测序样本call出的SNP数目通常是百万级甚至是千万级别，比如本文所用数据为17M SNP，如果直接使用这些SNP位点作为指标对个体进行区分，就会由于信息过于冗杂而无法把握重点，并造成计算资源和时间的浪费。PCA分析的过程就是从千万级别的SNP位点中提取关键信息，以便我们使用更少的变量就可以对样本进行有效的刻画和区分。</p><h4 id="2-PCA实践"><a href="#2-PCA实践" class="headerlink" title="2. PCA实践"></a>2. PCA实践</h4><p>在<a href="https://genome.cshlp.org/content/24/8/1308.long" target="_blank" rel="noopener">Gou et al, 2014</a>文章中，作者使用GCTA进行PCA分析，在本文中，还会讲解另外一种主流的PCA分析软件–EIGENSOFT中的smartpca。</p><p>软件下载链接：<br><a href="http://cnsgenomics.com/software/gcta/#Overview" target="_blank" rel="noopener">GCTA</a><br><a href="https://www.hsph.harvard.edu/alkes-price/software/" target="_blank" rel="noopener">EIGENSOFT</a></p><h5 id="GCTA进行PCA分析"><a href="#GCTA进行PCA分析" class="headerlink" title="GCTA进行PCA分析"></a>GCTA进行PCA分析</h5><ol><li>首先准备GCTA中PCA模块所需的输入文件，GCTA可以直接读取.bed , .bim , .fam文件，使用plink将vcf格式文件转换成上述三种文件,同时进行简单的过滤(–geno 0.05)。</li></ol><pre><code>#!/bin/bashplink=/software/biosoft/software/plink/plinktime $plink --vcf 60_dog.merge.vcf --geno 0.05 --dog --make-bed --out 60_dog_geno0.05 &amp;&amp; echo &quot;---- vcf2bed done -----&quot;</code></pre><ol start="2"><li>然后使用GCTA软件，–make-grm 生成个体对之间的遗传关系矩阵(genetic relationship matrix),并将GRM的下三角元素保存为二进制文件.grm.id , .grm.bin ， .grm.N.bin。<br>这里要强调一点，对于非人物种，要设定好染色体数目参数，–autosome-num。否则会因为不识别26以上的染色体编号而报错。</li></ol><pre><code>gcta=/software/biosoft/software/gcta_1.92.1beta6/gcta64time $gcta --bfile 60_dog_geno0.05 --make-grm --autosome-num 38 --out 60_dog_geno0.05 &amp;&amp; echo &quot;----make-grm done----&quot;</code></pre><ol start="3"><li>最后就是要进行PCA分析<br>使用 –pca 设置要生成主成分的数目，这里设置为4，一般来说就可以刻画出群体结构。<br>这一步会生成 .eigenval 和 .eigenvec 两个文件。.eigenval文件为各主成分可解释遗传信息的比例，.eigenvec文件为每个样本在top4主成分上的分解值。</li></ol><pre><code>time $gcta --grm 60_dog_geno0.05 --pca 4 --out 60_dog_geno0.05 &amp;&amp; echo &quot;----gcta-pca done----&quot;</code></pre><ol start="4"><li>补充样本所属子群信息<br>在生成的.eigenvec文件中，并没有包含样本所属子群信息，在进行可视化之前，需要添加上样本群体信息。样本较少时可以手动添加，样本数目较多时推荐写代码完成，避免错误。文章<a href="https://genome.cshlp.org/content/24/8/1308.long" target="_blank" rel="noopener">Gou et al,2014</a>中根据采样地点划分子群。添加上子群信息后，.eigenvec长这个样子。<br><img src="/img/population_analysis1-2.png" alt="p"><h5 id="EIGENSOFT进行PCA分析"><a href="#EIGENSOFT进行PCA分析" class="headerlink" title="EIGENSOFT进行PCA分析"></a>EIGENSOFT进行PCA分析</h5></li><li>使用plink将vcf格式文件转换成.bed , .bim , .fam文件，步骤同上，这里不再赘述。</li><li>smartpca需要提供三种输入文件，文件1记录每个样本在每个SNP位点的信息，文件2记录每个SNP位点的信息，文件3记录每个样本的性别和所属子群信息。<br>熟悉plink格式的同学应该知道.bed文件储存的就是genotype信息，.bim文件存储的就是SNP位点信息，那么我们只需要自己生成文件3就可以了。文件3格式如下，第一列为样本ID，第二列为性别（M，F，U），第三列为所属子群。<br><img src="/img/population_analysis1-3.png" alt="p"></li><li>接下来把所有参数写入一个文件中，就可以运行smartpca了，其中 numoutevec 是输出主成分的数目。<br><img src="/img/population_analysis1-4.png" alt="p"></li><li>运行smartpca，生成 .evec 和 .eval 文件。<pre><code>time /software/biosoft/software/EIG-6.1.4/bin/smartpca -p PCA.par &gt; smartpca.log &amp;&amp; echo &quot;----smartpca----done&quot;</code></pre>截图来看下 .evec 文件，两种软件运行结果差不多。<br><img src="/img/population_analysis1-5.png" alt="p"></li></ol><h4 id="3-绘制PCA散点图"><a href="#3-绘制PCA散点图" class="headerlink" title="3. 绘制PCA散点图"></a>3. 绘制PCA散点图</h4><p>通过得到的.evec和eval两个文件，这里使用python完成可视化，代码如下：</p><pre><code>import matplotlib.pyplot as pltimport collectionsimport rehash = collections.OrderedDict()eval_file = open(&quot;60_dog_geno0.05.eigenval&quot;,&quot;r&quot;)evec_file = open(&quot;60_dog_geno0.05.eigenvec&quot;,&quot;r&quot;)###  从.eval文件中读取top4主成分eval_1 = eval_file.readline()eval_2 = eval_file.readline()eval_3 = eval_file.readline()eval_4 = eval_file.readline()###  从.evec文件中读取在pc上的值for i in evec_file:    if re.match(r&#39;#&#39;,i.strip()):        continue    tmp = i.strip().split()[1:]    if tmp[-1] in hash.keys():        hash[tmp[-1]][&#39;1st&#39;].append(eval(tmp[1]))        hash[tmp[-1]][&#39;2nd&#39;].append(eval(tmp[2]))        hash[tmp[-1]][&#39;3rd&#39;].append(eval(tmp[3]))        hash[tmp[-1]][&#39;4th&#39;].append(eval(tmp[4]))    else:        hash[tmp[-1]] = hash.get(tmp[-1],collections.OrderedDict())        hash[tmp[-1]][&#39;1st&#39;] = hash[tmp[-1]].get(&#39;1st&#39;,[])        hash[tmp[-1]][&#39;2nd&#39;] = hash[tmp[-1]].get(&#39;2nd&#39;,[])        hash[tmp[-1]][&#39;3rd&#39;] = hash[tmp[-1]].get(&#39;3rd&#39;,[])        hash[tmp[-1]][&#39;4th&#39;] = hash[tmp[-1]].get(&#39;4th&#39;,[])        hash[tmp[-1]][&#39;1st&#39;].append(eval(tmp[1]))        hash[tmp[-1]][&#39;2nd&#39;].append(eval(tmp[2]))        hash[tmp[-1]][&#39;3rd&#39;].append(eval(tmp[3]))        hash[tmp[-1]][&#39;4th&#39;].append(eval(tmp[4]))### 绘制散点图，这里只绘制pc1和pc2,其他pc可按照下面代码逐一画出。fig = plt.figure(figsize=(20,10))ax = fig.add_subplot(1, 1, 1)            ### 2D figure#ax = fig.add_subplot(111,projection=&#39;3d&#39;)              ### 3D figuremark = [&#39;o&#39;,&#39;v&#39;,&#39;s&#39;,&#39;*&#39;,&#39;x&#39;,&#39;+&#39;]*10         ### 设置散点性状col = [&#39;b&#39;,&#39;g&#39;,&#39;y&#39;,&#39;r&#39;,&#39;c&#39;]*10               ### 设置散点颜色for m,n in enumerate(hash.keys()):    ### 逐点画出    ax.scatter(hash[n][&#39;1st&#39;],hash[n][&#39;2nd&#39;],c=col[m],s=75,marker=mark[m],label=n,alpha=0.7)ax.legend(loc=&#39;best&#39;,scatterpoints=1,fontsize=&#39;12&#39;,framealpha=0)ax.set_xlabel(&#39;Eigenvector1 ({}%)&#39;.format(float(&#39;%.2f&#39; % eval(eval_1))),fontsize=13,fontweight=&#39;bold&#39;)ax.set_ylabel(&#39;Eigenvector2 ({}%)&#39;.format(float(&#39;%.2f&#39; % eval(eval_2))),fontsize=13,fontweight=&#39;bold&#39;)#### 保存图片save_FileName = &#39;60dog_geno0.05_gcta_pc1_pc2.png&#39;plt.savefig(save_FileName,dpi=400,bbox_inches=&#39;tight&#39;)</code></pre><p>PCA散点图如下<br><img src="/img/population_analysis1-1.png" alt="p">#### 小结<br>PCA运用方差分解，将海量SNP的差异反映在二维坐标图上，坐标轴轴取对样品差异性解释度最高的两个或三个特征值，样本SNP位点信息越相似，反映在PCA图中的距离越近。PCA可以帮助我们清楚掌握手上样本的群体结构，并有效检测出离群样本，为下游分析减少不必要的麻烦，同时，实现PCA分析的方法很多，PCA结果图也简单易懂，称得上是低调实力派。<br>最后强调一点，PCA分析是降维，不是聚类，希望大家不要搞混了。<br>对PCA理论和分析过程感兴趣的同学，可以进一步看下<a href="https://blog.csdn.net/zhongkelee/article/details/44064401" target="_blank" rel="noopener">这篇文章</a>。</p><p><strong>谢谢大家赏脸看到这里，在本篇文章中，主要学习了PCA分析的基本过程，在下篇文章中，我们将接着学习系统发生树构建和祖先成分分析，精彩不容错过，请持续关注我们！</strong></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>Genome Res. 2014 Aug;24(8):1308-15. doi: 10.1101/gr.171876.113. Epub 2014 Apr 10.</p><p><a href="http://blog.csdn.net/zhongkelee/article/details/44064401" target="_blank" rel="noopener">http://blog.csdn.net/zhongkelee/article/details/44064401</a></p><p><img src="/img/vazyme.png" alt="vazyme"></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> population genetics </tag>
            
            <tag> pca </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始入门R语言编程</title>
      <link href="/2019/05/10/r-language1/"/>
      <url>/2019/05/10/r-language1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="R语言编程入门"><a href="#R语言编程入门" class="headerlink" title="R语言编程入门"></a><em>R语言编程入门</em></h1><h3 id="写在前面的"><a href="#写在前面的" class="headerlink" title="写在前面的"></a>写在前面的</h3><blockquote><p>上期推文介绍了如何使用R语言编程进行样本间相关性分析，主要涉及了R语言矩阵、循环、统计分析函数、ggplot2、corrplot等函数包的使用，涉及的知识面较多，如果不是经常做生物信息或者是编程出家，很难在短时间内适应编程模式。其实，一旦适应了编程，很多问题都能轻松迎刃而解。毕竟计算机语言也是一门语言，和人与人之间打交道一样，人与计算机打交道也是很容易的。本次推文以<strong>引导大家入门R语言编程为目的</strong>，用尽可能精炼的内容教学R语言。认识R语言首先认识R语言的数据类型及控制结构。掌握这些基础以后，再认识R语言的函数包。经过一定时间的练习就可以熟悉R语言了。</p></blockquote><h3 id="R语言数据类型1：向量"><a href="#R语言数据类型1：向量" class="headerlink" title="R语言数据类型1：向量"></a>R语言数据类型1：向量</h3><p>向量是R语言最基本的数据类型。R语言中向量和大学时候学的线性代数一样，是由一行或者一列数据组成的变量。</p><pre><code>x&lt;-c(1,2,3,4,5) #把向量赋值给x，c是连接函数。此时x就是由数字1到5组成的向量length(x) #获取向量长度x[3]#x的第三个元素x[-1:-2] #删除x前两个元素x&lt;-x[-1:-2] #删除x前两个元素并保存b&lt;-seq(from=1,to=100,by=2) #seq是生成等差数列函数，from是数列起始值to是终止值，by是公差</code></pre><h3 id="R语言数据类型2：矩阵"><a href="#R语言数据类型2：矩阵" class="headerlink" title="R语言数据类型2：矩阵"></a>R语言数据类型2：矩阵</h3><p>R语言矩阵可以理解为多个长度相同的向量按照行或列排列而成的多维向量，R语言矩阵与线性代数中的矩阵稍有不同，不同点在于矩阵的乘法计算上，线性代数中矩阵乘法计算方法为设A为 mxp 的矩阵，B为 pxn 的矩阵，那么称 mxn 的矩阵C为矩阵A与B的乘积,其中矩阵C中的第 i行第 j列元素可以表示为</p><p>$$AB_{ij}=\sum_{k=1}^p a_{ik}b_{kj}=a_{i1}b_{1j}+a_{i2}b_{2j}+…+a_{ip}b_{pj}$$</p><p>但是R语言中矩阵乘法是对应元素做乘积。举例为</p><pre><code>f&lt;-cbind(c(1,2,3),c(4,5,6)) #将两个向量按列捆绑可得得到矩阵,如果想按照行向量捆绑为矩阵用rbind函数z&lt;-cbind(c(1,2,3),c(4,5,6))f*z [,1] [,2][1,]    1   16[2,]    4   25[3,]    9   36x&lt;-matrix(c(1,2,3,4,5,6),ncol=2,nrow=3)#另外一种矩阵赋值方式，ncol定义矩阵的列数，nrow定义矩阵行数，另外ncol(x)或者nrow(x)则可以求矩阵的列数或行数。x[1,2]#查看矩阵第1行第2列元素,当然如果想查看矩阵第一行则为x[1,]查看第二列为x[,2]。</code></pre><h3 id="R语言数据类型3：列表"><a href="#R语言数据类型3：列表" class="headerlink" title="R语言数据类型3：列表"></a>R语言数据类型3：列表</h3><p>列表是一种特殊的向量，不同之前的向量。之前的向量可以理解为原子型，列表中可以保存为不同格式的数据。可以是字符串型、数值型等。举例为</p><pre><code>j&lt;-list(name=&quot;joe&quot;,salary=55000,union=T)#其中name，salary，union理解为列表的标签，等号后面的量理解为列表标签的值，可以一个标签对应多个值，但是列表的标签具有唯一性！Names(j)#获取列表的所有标签。当然如果想使用其他方法查询列表第2个标签可以使用就j$salary，j[2]，或者j[[2]]。两者的区别读者可以通过实践发现。</code></pre><h3 id="R语言数据类型4：数据框"><a href="#R语言数据类型4：数据框" class="headerlink" title="R语言数据类型4：数据框"></a>R语言数据类型4：数据框</h3><p>数据框与矩阵有很多相似之处，很多矩阵适用的函数数据框同样适用。与矩阵不同的是，数据框里面的数据类型可以不一致，但矩阵维数必须相等，即各列数据长度相等。以一个实例简单介绍数据框</p><pre><code>a&lt;-c(&quot;apple&quot;,&quot;pen&quot;)b&lt;-c(17,14)c&lt;-data.frame(a,b,stringsAsFactors = F) #创建一个简单的数据框，由于矩阵所用的函数多数都适应于数据框，所以这里不再详细介绍。具体操作读者们可以自行在R语言上实践。</code></pre><h3 id="R语言数据类型5：因子"><a href="#R语言数据类型5：因子" class="headerlink" title="R语言数据类型5：因子"></a>R语言数据类型5：因子</h3><p>因子在实际的数据分析中用到的场合不多。在R语言中，因子（factor）表示的是一个符号一个编号或者一个等级。以一个实际例子让读者理解因子。</p><pre><code>x&lt;-c(100,1,4,9,1320)x&lt;-factor(x) #对向量X进行因子化处理[1] 100  1    4    9    1320Levels: 1 4 9 100 1320</code></pre><p>从例子中可以看出，因子实际是为向量数据中的每一个元素赋予一个级别。例如元素100，它对应的level是100，比第二个元素1对应的level大，所以在level的排序上，100在第三个level上。</p><h2 id="R语言控制结构"><a href="#R语言控制结构" class="headerlink" title="R语言控制结构"></a>R语言控制结构</h2><p>常用的两种控制结构为判断和循环，简单地说掌握了基本控制结构和R语言的数据类型是可以进行数据分析的，毕竟任何一种编程语言只要掌握了语法，剩下的就看个人的数学与逻辑素养了。</p><p>1.判断结构：通常为if（条件）{命令}else{命令}类型，也有if…else if…else。也可以只有一个if。举例介绍判断结构语法，输入一个数，如果它大于等于10，输出Y，如果大于等于5小于10输出T，否则输出N</p><pre><code>x&lt;-6if(x&gt;=10){print(&quot;Y&quot;)}else if(x&lt;10 &amp;&amp; x&gt;=5){print(&quot;T&quot;)}else{print(&quot;N&quot;)}</code></pre><p>2.循环结构：R语言中for循环使用较多，通常结构为for(条件){命令}。以简单例子举例for循环语法，定义一个数值向量，将向量中每个元素的平方赋值给新向量。</p><pre><code>x&lt;-c(1:9)y&lt;-NULLfor (i in 1:length(x)) {   y&lt;-c(y,(x[i])^2)}print(y)[1]  1  4  9 16 25 36 49 64 81</code></pre><h2 id="综合运用R语言编程"><a href="#综合运用R语言编程" class="headerlink" title="综合运用R语言编程"></a>综合运用R语言编程</h2><blockquote><p>以上是R语言编程入门最基本的语法，只有逐渐熟悉这些语法，才可以更进一步使用R语言，下面以上次推文的数据为例子，为大家讲一下如何综合运用R语言知识。上次的推文中是利用RNA-seq的reads count数据计算样本间的重复性分析。另外小明师兄的上篇推文RNA-seq中的那些统计学问题(一)为什么是负二项分布，这篇推文从统计学角度出发推理论证了RNA-seq的reads count数据为什么符合负二项分布，<strong>下面我们从R语言编程开始利用实际RNA-seq的readscount数据证明一下为什么是负二项分布</strong></p></blockquote><p>根据负二项分布的性质，均值和方差为<br>$$\mu={pr}/{(1-p)}$$<br>$$\sigma^2={pr}/(1-p)^2$$<br>将P用U表示并带入方差表达式得到</p><p>$$\sigma^2=\mu^2/r+\mu$$<br>根据数学知识可以看出方差是均值的二次函数。所以我们这次综合利用R语言编程的知识进行证明。</p><pre class=" language-R"><code class="language-R">readcount<-read.table("readscount.txt",header=T,sep="\t") #读取readscout数据readcount<-readcount[,2:4]#由于第2到4列是一个处理的三个生物学重复，所以就以这三个生物重复的readscount值进行分析readcount<-readcount[rowSums(readcount)>1,] #过滤掉全为0的行x<-NULL #先定义储存每个基因表达均值的变量y<-NULL #定义储存每个基因表达方差的变量for (i in 1:nrow(readcount)) {  x<-c(x,mean(as.numeric(readcount[i,]))) #在循环中依次求每个基因表达的均值，并赋值到x向量中  y<-c(y,var(as.numeric(readcount[i,]))) #在循环中依次求每个基因表达的方差，并赋值到y向量中}data<-data.frame(x=x,y=y) #将x和y捆绑为数据框a<-quantile(data[,1],c(0.25,0.75),na.rm = T) #求基因表达均值的分位数，quantile函数是求分位数函数，na.rm=T是移除NA值，这里的目的是去除掉太大或者太小的数据b<-quantile(data[,2],c(0.25,0.75),na.rm = T)#求基因表达方差的分位数data<-data[data[,1]<=as.numeric(a[2]) && data[,1]>=as.numeric(a[1]),]#将data数据框中的基因表达均值列满足在25%~75%分位数之间的行保留data<-data[data[,2]<=as.numeric(b[2]) && data[,2]>=as.numeric(b[1]),]#将data数据框中的基因表达方差列满足在25%~75%分位数之间的行保留ggplot(data = data2,aes(x=x,y=y))+geom_point()+geom_smooth(method = "gam",formula=y~poly(x,2)) #使用ggplot2绘制均值-方差散点图，并进行拟合，拟合方法为平滑曲线拟合</code></pre><p><img src="/img/r-language1-1.png" alt="p"><br>从图片中看出，尽管过滤掉部分数据后还是存在个别极端数据，总体的数据分布曲线满足二次函数分布。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>理解R语言编程的五个数据结构：向量、矩阵、列表、数据框、因子，以及两种控制结构，循环和判断。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p>《R in action》<br><img src="/img/vazyme.png" alt="vazyme"></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> R </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅说动力学模型（下篇）</title>
      <link href="/2019/05/08/dynamic-model2-md/"/>
      <url>/2019/05/08/dynamic-model2-md/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>浅说动力学模型（下篇）<br>原创： 赵洪龙 宇宙实验媛<br><img src="/img/dynamic_model2-1.png" alt="p"><br>图1. 数学建模在生物学研究中的应用范式<br>书接上文<a href="http://www.universebiologygirl.com/2019/04/09/dynamic-model1" target="_blank" rel="noopener">浅说动力学模型（上篇）</a>，由于本人主要研究植物学代谢建模，下面就举例说明使用模型在植物生理研究中取得的一些重要成就。在过去的研究中，植物领域对光合作用的研究积累了大量的数据，这为光合作用相关的动力学建模提供了数据基础。研究者们已经从<strong>细胞代谢层面(1)、叶片层面(2, 3)、植株水平和群体水平分别构建了模型(4)。</strong> 利用这些模型已经成功预测出了限制光合作用的关键过程，并且部分预测结果已经通过基因工程改造进行了验证。<br>自然条件下，植物生长的环境总是不断变化的，比如一阵微风吹过就会导致植物叶片接收的光发生改变。上层叶片摆动，下层叶片就会处于一明一暗的不断变化中。正如人眼睛的瞳孔在黑暗条件下放大、在明亮条件下会缩小，而闪光对眼睛有很强的刺激作用一样，闪光对植物而言也是一种非常严重的胁迫，会导致光合作用电子传递链出现损伤，从而抑制光合作用。植物有很多机制能耗散过剩的能量和修复这种闪光带来的电子传递链损伤，以防止被‘烧伤’并最大化光能的利用效率。以前没有一个合适的系统模型评估过这种能量耗散途径对作物产量所造成的损失，故而也一直没有明确的方案能通过减少这种损失来提高作物产量的潜力。Zhu等构建的作物群体中叶片光合作用能量分配的动力学模型，结合光线追踪算法对这个过程进行了理论分析。其预测显示，如果能够加快这个修复过程，作物的生产能力能增加20%左右(5)。<br>为了能更好地理解这个原理，我们给出了示意图（图2）。叶片在强光条件下的时候，一般来说植物的光合能力相对要高一些，而过多的能量会通过其他的途径耗散，以免叶片吸收过多的能量无法被转化成化学能导致叶片‘烧伤’。这对大部分植物叶片来讲是一种很好的防御机制（叫做光损伤防御）。然而，当植物从强光条件下转移到低光条件下的时候（t0时刻），能量往往成为光合能力的一种限制条件。此时，那些防御途径仍然“大手大脚”地耗散光能，减少了分配到化学能转化的分量。在数分钟或者数小时（假设为t0 – t2）的低光下，这些防御途径耗散的能量会慢慢减少，光合同化能力慢慢增加，我们把这段时间称之为恢复时间。就像我们从太阳底下走进相对比较暗的房间一样，眼睛会突然感觉到很暗，但过一段时间后房间里面就会变得‘亮起来’。从图2中我们可以很容易理解，如果减少这段恢复时间，就能够增加总的光能利用效率。因此，Zhu等2004年建立的模型主要描述了：<br>**1. 植物冠层中上下不同层次的点在一天的光强变化条件下的太阳辐射截获量；</p><ol start="2"><li>截获的太阳辐射与光合能力之间的对应关系；</li><li>接受的太阳辐射量变化时，植物由于光损伤防御机制的存在而引起的能量损失（及温度的影响）；</li><li>通过减少光损伤防御恢复时间能给作物的光合生产能力提升带来的潜在空间。<strong><br><img src="/img/dynamic_model2-2.png" alt="p"><br>图2. 植物叶片从强光变到至弱光条件下时光损伤防御恢复机制的简单示意图。红色箭头表示叶片暴露在不同的光下。如果能把光损伤防御恢复的时间从t2缩短至t1，将有可能提高整个群体光合生产能力的12-30%。历经12年其合作团队通过基因工程手段进行改造，加快了这种光损伤恢复的速度，实现了烟草的光合作用能力及生产能力的大幅增加，成功验证了这一预测(6)。不仅如此，Zhu等建立的卡尔文循环代谢模型结合进化算法，预测了光合作用碳同化代谢过程中限制其效率的关键酶，这些预测与报道的实验结果一致(1)，因此也被采纳为作物改良的主要策略之一(7, 8)。Wang等建立的C4光合作用代谢模型系统解析了C4光合作用代谢过程高效的互作机理(9)。</strong>利用动力学模型，还可以为将来合成生物学导入新的代谢途径提供理论分析工具。** 比如通过参考模型计算和分析的结果进行基因工程改造，增加微生物中特定代谢物的产量，这在微生物研究的应用中较为广泛(10)；或者增加植物的次生代谢产物的产量(11) 等。<br>有关复杂代谢系统生物学建模的方法，Zhu(12)和Zhao(13)等均分别进行了综述，感兴趣的读者可参考阅读。<br>展望动力学模型虽然近些年来，随着数据测量技术和计算能力的飞速提升，系统生物学的发展势头迅猛，也取得了一些成就，然而现在动力学模型的构建过程中依然存在一些挑战。首先，动力学模型是基于具体过程的一类模型。而生物学过程总是交织成多维度的复杂网络，针对具体问题解析这些关系是一件繁琐的事情，因此模型构建是一件十分耗时的工作，且对研究的问题需要有深厚的知识背景，况且，现在我们并没有完全了解所有的生命过程。更甚，对于一个模型的参数化和验证而言，难以收集到一套完整而系统的数据集。数据库和文献中收集的数据均非常离散，环境、物种和测量过程的差异都会导致模型参数化和验证过程陷入困境。第三，模型参数化的过程和方法需要进一步提升并规范化。<br>笔者认为，决定未来动力学模型构建与生物学研究耦合的几个重要因素如下：</li></ol><ul><li>第一，生物学测量技术需要进一步发展，高通量、高标准和高质量的数据是模型构建的基石。虽然目前组学数据的增长速度史无前例，但测量方法之间的差异、规范性问题、条件和细胞特异性问题等依旧是建模的重要拦路虎。</li><li>第二，多背景交叉融合需要进一步加强。生物学与化学、物理学、数学、计算机科学等学科之间的交流能在确保重要信息的前提下更好地将复杂生物学问题简单化，从而确保模型具有更强的生物学预测能力和应用价值。</li><li>第三，模型需要不断被优化和更新。所有的模型都不可能是完美的，需要针对具体问题进行结构和参数的进一步优化，因此需要构建一些大型的数据存储和模型分析平台，从而进入用模型帮助数据分析、用数据优化和修正模型的良性循环。至此，方能更好地将模型应用于生物学研究，造福于人类。</li></ul><h1 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h1><p>Zhu XG, de Sturler E, &amp; Long SP (2007) Optimizing the distribution of resources between enzymes of carbon metabolism can dramatically increase photosynthetic rate: a numerical simulation using an evolutionary algorithm. Plant physiology 145(2):513-526.Tholen D &amp; Zhu XG (2011) The mechanistic basis of internal conductance: a theoretical analysis of mesophyll cell photosynthesis and CO2 diffusion. Plant physiology 156(1):90-105.Xiao Y, Tholen D, &amp; Zhu XG (2016) The influence of leaf anatomy on the internal light environment and photosynthetic electron transport rate: exploration with a new leaf ray tracing model. Journal of experimental botany 67(21):6021-6035.Song Q, Chu C, Parry MA, &amp; Zhu XG (2016) Genetics-based dynamic systems model of canopy photosynthesis: the key to improve light and resource use efficiencies for crops. Food Energy Secur 5(1):18-25.Zhu XG, Ort DR, Whitmarsh J, &amp; Long SP (2004) The slow reversibility of photosystem II thermal energy dissipation on transfer from high to low light may cause large losses in carbon gain by crop canopies: a theoretical analysis. Journal of experimental botany 55(400):1167-1175.Kromdijk J, et al. (2016) Improving photosynthesis and crop productivity by accelerating recovery from photoprotection. Science 354(6314):857-861.Miyagawa Y, Tamoi M, &amp; Shigeoka S (2001) Overexpression of a cyanobacterial fructose-1,6-/sedoheptulose-1,7-bisphosphatase in tobacco enhances photosynthesis and growth. Nat Biotech 19(10):965-969.Simkin AJ, McAusland L, Headland LR, Lawson T, &amp; Raines CA (2015) Multigene manipulation of photosynthetic carbon assimilation increases CO(2) fixation and biomass yield in tobacco. J Exp Bot 66(13):4075-4090.Wang Y, Brautigam A, Weber AP, &amp; Zhu XG (2014) Three distinct biochemical subtypes of C4 photosynthesis? A modelling analysis. Journal of experimental botany 65(13):3567-3578.Colón AM, Sengupta N, Rhodes D, Dudareva N, &amp; Morgan J (2010) A kinetic model describes metabolic response to perturbations and distribution of flux control in the benzenoid network of Petunia hybrida. The Plant Journal 62(1):64-76.Xin CP, Tholen D, Devloo V, &amp; Zhu XG (2015) The benefits of photorespiratory bypasses: how can they work? Plant physiology 167(2):574-585.Zhu XG (2010) Systems-level modeling–a new approach for engineering efficient photosynthetic machinery. Journal of biotechnology 149(3):201-208.Zhao H, Xiao Y, &amp; Zhu XG (2017) Kinetic Modeling of Photorespiration. Methods Mol Biol 1653:203-216.<br><img src="/img/vazyme.png" alt="vazyme"></p>]]></content>
      
      
      <categories>
          
          <category> Bio Cooking </category>
          
      </categories>
      
      
        <tags>
            
            <tag> dynamic model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNA-seq中的那些统计学问题（一）为什么是负二项分布？</title>
      <link href="/2019/05/07/rna-seq-data-analysis1/"/>
      <url>/2019/05/07/rna-seq-data-analysis1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1-转录组数据统计推断的难题"><a href="#1-转录组数据统计推断的难题" class="headerlink" title="1. 转录组数据统计推断的难题"></a>1. 转录组数据统计推断的难题</h2><p>在RNA-seq中进行两组间的差异分析是最正常不过的了。</p><p>我们在其它实验中同样会遇到类似的分析，通常，我们可以用方差分析判定两组“分布”数据间是否存在显著差异。原理是：当组间方差大于组内方差（误差效应），并且统计学显著时，则认为组间处理是可以引起差异的。</p><p>那这不就是咱们学过的统计学里普普通通的假设检验问题吗？用熟悉的算法简单地进行计算，分分钟就能搞定吧——凸样凸拿衣服，骚年要是事情都那么简单，要科学家干嘛，问题就在于：常规方法搞不定啊！</p><p>其实统计学家也很无奈啊，看看我们转录组实验得到的这些数据吧：我们的实验只进行少得可怜的生物学重复（n&lt;10），而且，任何基因的表达量都不能是负数，这些数据并不符合正态分布，用于表征表达量的counts是非连续的（芯片信号是连续的），RNA-seq数据的离散通常是高度扭曲的，方差往往会大于均值……，就这些奇怪的特征，使得准确估计方差并没有想象的那么容易。</p><p>我们面临两个核心问题：</p><ul><li>基因表达数据适合用什么统计学分布进行差异显著性检验？</li><li>如何利用少量生物学重复数据估算基因表达的标准差？</li></ul><h2 id="2-泊松分布-or-负二项分布？"><a href="#2-泊松分布-or-负二项分布？" class="headerlink" title="2. 泊松分布 or 负二项分布？"></a>2. 泊松分布 or 负二项分布？</h2><p>从统计学的角度出发，进行差异分析肯定会需要假设检验，通常对于分布已知的数据，运用参数检验结果的假阳性率会更低。转录组数据中，raw count值符合什么样的分布呢？</p><p>count值本质是reads的数目，是一个非零整数，而且是离散的，其分布肯定也是离散型分布。对于转录组数据，学术界常用的分布包括<strong>泊松分布 (poisson)</strong>和<strong>负二项分布 (negative binomial)</strong>两种。</p><h3 id="2-1-为什么泊松分布不行？"><a href="#2-1-为什么泊松分布不行？" class="headerlink" title="2.1. 为什么泊松分布不行？"></a>2.1. 为什么泊松分布不行？</h3><p>首先有必要简单地介绍一下泊松分布</p><blockquote><p>泊松分布适合于描述单位时间（或空间）内随机事件发生的次数（事件发生的次数只能是离散的整数）。如某一服务设施在一定时间内到达的人数，电话交换机接到呼叫的次数，汽车站台的候客人数，机器出现的故障数，自然灾害发生的次数，一块产品上的缺陷数，显微镜下单位分区内的细菌分布数等等。</p><p>$$P(X=k)=\frac{\lambda^k }{k!}e^{-\lambda},\quad k=0,1,…$$</p><p>泊松分布大概长这样：</p></blockquote><p><img src="/img/rna-seq_analysis1-1.png" alt="p"></p><blockquote><p>λ是波松分布所依赖的唯一参数。 λ值愈小分布愈偏倚， 随着λ的增大 ， 分布趋于对称。 当λ=20时分布接近于正态分布；当λ=50时， 可以认为波松分布呈正态分布。</p></blockquote><p>在数据分析的早期，确实有学者采用泊松分布进行差异分析，但是发展到现在，几乎全部都是基于负二项分布了，究竟是什么因素导致了这种现象呢？为了解释这个问题，我们必须提到一个概念 <strong>overdispersion</strong>。</p><p>dispersion指的是离散程度，研究一个数据分布的离散程度，我们常用方差这个指标。<strong>对于泊松分布而言，其均值和方差是相等的，但是我们的数据确不符合这样的规律</strong>。通过计算所有基因的均值和方差，可以绘制如下的图片：</p><p><img src="/img/rna-seq_analysis1-2.png" alt="p"><br>横坐标为基因在所有样本中的均值，纵坐标为基因在所有样本中的方差，直线的斜率为1，代表泊松分布的均值和方差的分布。可以看到，真实数据的分布是偏离了泊松分布的，方差明显比均值要大。</p><p>如果假定总体分布为泊松分布， 根据我们的定量数据是无法估计出一个合理的参数，能够符合上图中所示分布的，这样的现象就称之为overdispersion。</p><p>由于真实数据与泊松分布之间的overdispersion，<strong>选择泊松分布分布作为总体的分布是不合理</strong>。</p><p>以上只证明了泊松分布是个不太恰当的分布估计，那<strong>怎么证明负二项分布就是合适的分布估计呢？</strong></p><h3 id="2-2-为什么负二项分布行？"><a href="#2-2-为什么负二项分布行？" class="headerlink" title="2.2. 为什么负二项分布行？"></a>2.2. 为什么负二项分布行？</h3><p>主要是从均值与方差之间的关系去证明</p><p>同样的，也先简单介绍一下负二项分布：</p><blockquote><p>二项分布描述的是n重伯努利实验，在n重贝努利试验中，事件A恰好发生x(0≤x≤n)次的概率为：</p><p>$$P_n(x)=C_n^x p^x(1-p)^{n-x}$$</p><p>它的概率分布图如下：</p></blockquote><p><img src="/img/rna-seq_analysis1-3.png" alt="p"> </p><blockquote><p>负二项分布描述的<strong>也是伯努利实验</strong>，不过它的目标事件变成了：对于Bernoulli过程，我们设定，当某个结果出现固定次数的时候，整个过程的数量，比如我们生产某个零件，假设每个零件的合格与否都是相互独立的，且分布相同，那么当我们生产出了五个不合格零件时，一共生产了多少合格的零件，这个数量就是一个<strong>负二项分布</strong>，公式如下：</p><p>$$f(k;r;p)=P(x=k)=C_{r+k-1}^k p^k(1-p)^r$$</p><p>该公式描述的是，在合格率为p的一堆产品中，进行连续有放回的抽样，当抽到r个次品时，停止抽样，此时抽到的正品正好为k个的概率</p><p>它的概率分布如下：</p></blockquote><p><img src="/img/rna-seq_analysis1-5.png" alt="p"><br>负二项分布的均值和方差分别为：</p><p>$$\mu=\frac{pr}{1-p}$$</p><p>$$\sigma^2=\frac{pr}{(1-p)^2}$$</p><p>将p用μ表示，得到：</p><p>$$p=\frac{\mu}{\mu+r},\quad 1-p=\frac{r}{\mu+r}$$</p><p>将上一步推出的p和1-p带入到方差的表达式中，得到：</p><p>$$\sigma^2=\frac{\mu^2}{r}+\mu$$</p><p>记<code>1/r=α</code>，则</p><p>$$\sigma^2=\mu+\alpha\mu^2$$</p><p>从上面的式子可以看出，均值是方差的二次函数，方差随着均值的增加而进行二次函数形式的递增，正好符合上文 <code>2.1. 为什么泊松分布不行？</code> 部分均值与方差分布图的情况</p><p>其中<code>α</code>和<code>r</code>被称为<strong>dispersion parameter</strong></p><p>负二项分布与泊松分布的关系，可以用<code>α</code>或<code>r</code>推出：</p><blockquote><p>当 <code>r -&gt; ∞</code> 时，<code>α -&gt; 0</code>，此时 σ<sup>2</sup>= μ，为泊松分布；</p><p>当 <code>r -&gt; 0</code> 时，<code>α -&gt; ∞</code>，此时overdispersion</p></blockquote><h2 id="3-方差估计"><a href="#3-方差估计" class="headerlink" title="3. 方差估计"></a>3. 方差估计</h2><p>在生物学重复很少时，我们是很难准确计算每个基因表达的标准差的（相当于这个数据集的离散程度）。我们<strong>很可能会低估数据的离散程度</strong>。</p><p>被逼无奈的科学家提出了一个假设：表达丰度相似的基因，在总体上标准差应该也是相似的。我们把不同生物学重复中表达丰度相同的基因的总标准差取个平均值，低于这个值的都用这个值，高于这个值的就用算出来的值。</p><p><img src="/img/rna-seq_analysis1-6.png" alt="p"></p><hr><p>参考资料：</p><p>(1) 【生信修炼手册】负二项分布在差异分析中的应用</p><p>(2) 【 生信百科】转录组差异表达筛选的真相</p><p>(3) 【生信媛】RNA-seq分析中的dispersion，你知道吗？</p><p>(4) H. J. Pimentel, et al. Differential analysis of RNA-Seq incorporatingquantification uncertainty. bioRxiv, 2016</p><hr><p>注：本文章已经发表于微信公众号<a href="https://mp.weixin.qq.com/s/KtyyQMSFO7-ThQHKFfuj3Q" target="_blank" rel="noopener">《宇宙实验媛》</a>，如需转载，请联系本人或该公众号</p><p>欢迎关注<strong>宇宙实验媛</strong><br><img src="/img/vazyme.png" alt="vazyme"></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>运用AI对科研文章中的图片进行绘图</title>
      <link href="/2019/05/07/ai-drawing/"/>
      <url>/2019/05/07/ai-drawing/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>TMJ universebiologygirl<br>本次视频主要以《Polarizing brain organoids》这篇文章内的Fig. 1为例，使用Adobe Illustrator CS6 对Fig.1 进行绘图，供大家学习参考。此次视频主要涉及的内容为“基础图形的绘制”、“渐变色添加”、“图形反光绘制”、“路径查找器工具的使用”等。<br><a href="https://v.qq.com/x/page/x0866u7tcnv.html" target="_blank" rel="noopener">AI drawing</a><br>下面将对绘图过程进行展开说明：<br><strong>第一步：文件→新建→对画板进行设置。</strong><br>一般为方便投稿，配置文件选择“打印”，大小选择“A4”，颜色模式CMYK，(具体可根据投稿要求选择，CMYK模式是彩色印刷时采用的一种套色模式) （视频内设置仅为画图方便所设）。<br><img src="/img/ai_drawing1.png" alt="p1"><br><strong>第二步：绘制图a的图片的基本形态。</strong><br>采用左边工具栏“画笔工具”，按住鼠标，绘制出想要的图形（画出大致轮廓即可，可后期通过锚点调整）。<br><img src="/img/ai_drawing2.png" alt="p1"><br><strong>第三步：通过锚点调整形状，主要用到两个工具添加/删除锚点工具、直接选择工具。</strong><br>直接选择工具可对锚点进行调整，从而达到调整基本形状的目的。若第二步画出的基本形状的锚点不足以调整，可通过添加/删除锚点工具，在线条上添加或删除后，再用直接选择工具调整。<br>转换工具可使锚点周围线条变得平滑。（如下图标出的红框所示）<br><img src="/img/ai_drawing3.png" alt="p1"><br><strong>第四步：填充背景颜色。</strong><br>该步骤使用到几个工具：吸管工具、填色、描边、渐变。将图形填充后可用画笔用具将边缘颜色画好，同样可用锚点、直接选择工具对边缘形状进行调整。吸管工具可对已知颜色进行选取。<br><img src="/img/ai_drawing4.png" alt="p1"><br><strong>第五步：绘制培养皿。</strong><br>先画出一个基本的椭圆形，再使用3D工具对这个椭圆形进行3D加工。<br><img src="/img/ai_drawing5.png" alt="p1"><br>红框界面可调整视觉角度。<br><img src="/img/ai_drawing6.png" alt="p1"><br>调整结束后可采用对象→拓展外观，然后添加描边。（本视频中采用的是添加线条的方法，没有拓展外观工具方便）。<br><img src="/img/ai_drawing7.png" alt="p1"><br>随后可用矩形工具、椭圆工具等画出培养皿底部，培养物等基本形状。<br><img src="/img/ai_drawing8.png" alt="p1"><br><strong>第六步：继续用矩形、椭圆工具画出圆底烧杯的基本图形框架。</strong><br>用窗口→路径查找器→形状模式→联集，对图形轮廓进行合并（可自己尝试多种路径查找器功能，拼接出自己想要的图案）。其余填色等步骤与前文所提及的步骤异曲同工。<br><img src="/img/ai_drawing9.png" alt="p"><br><strong>第七步：绘制器皿的反光和阴影。</strong><br>用弧形工具绘制出曲线后，选择线条形状，如“等比”等，再通过锚点工具、直接选择工具对线条进行调整即可。阴影的绘制可采用镜像工具对已画出的反光图形进行翻转。<br><img src="/img/ai_drawing10.png" alt="p"><br><strong>第八步：先画出一个椭圆，改成白色的渐变色，采用渐变工具对渐变方向做调整，对透明度作出调整（可自行调节到需要的透明度），使用径向模糊工具作出调整。</strong><br>其他步骤与上述步骤均相似，不再赘述。<br><img src="/img/ai_drawing11.png" alt="p"><br>Tip：在word等工具性软件常用的通用快捷键如下（常用的复制粘贴就不说啦）<br>  撤销：Ctrl+z<br>  剪切：ctrl+x<br>  加粗：ctrl+b<br>  绘图时希望圆形呈正圆或画出的直线是笔直不倾斜时，按住shift再进行拖拽放大/缩小<br>  AI里整个图形放大缩小，需要按住Alt而不是Ctrl。<br>参考文献：<a href="https://www.nature.com/articles/s41587-019-0084-4）" target="_blank" rel="noopener">https://www.nature.com/articles/s41587-019-0084-4）</a><br><img src="/img/vazyme.png" alt="vazyme"></p>]]></content>
      
      
      <categories>
          
          <category> Paper writing </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>R语言进行样本间相关性分析</title>
      <link href="/2019/05/07/correlation-analysis-in-R/"/>
      <url>/2019/05/07/correlation-analysis-in-R/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>熊东彦  universebiologygirl</p><h1 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h1><pre><code>生物学数据分析中相关性分析是十分重要的一个环节，但这个环节又经常被忽视。以生物信息学分析为例：非生物信息专业的学生通常在分析实验获得测序数据时都会忽略这个问题。大多数非专业生物信息学背景学生的生物信息数据分析技巧都是从网上的一些教程或者是培训机构的视频中学到的，遗憾的是培训机构仅仅只是教会了你跑一个组学分析的流程，其中涉及的很多重要的细节并没有教给你。因此，从细节着手进行相关性分析显得尤为重要。例如：在转录组测序时候通常要选择3个生物学重复。但是选择了3个生物学重复后送去测序，拿到数据跑完一遍流程真的就可以用来进行差异表达分析吗？绝大多数情况下是可以的，但如果你研究的是细菌、病毒这些变异相对较多的物种，你的一个处理的不同生物学重复可能就不一定是一致的了。如果这种情况发生，那就要剔除这组变异数据。用剩下的数据进行差异表达分析。毕竟设置3个生物学重复一方面是保证一定的重复性，一方面也是预防某个重复值不能用的情况。当然在其他生物学数据分析中，也有这种情况。今天介绍一个利用R语言编程来进行相关性分析的方法。毕竟当样本数据量较大的情况，手动挨个做相关性分析非常费时间。同时用R语言做完相关性分析后的最大特点是可视化，可以直接提升文章数据的档次感。</code></pre><h1 id="手把手教程呈现："><a href="#手把手教程呈现：" class="headerlink" title="手把手教程呈现："></a>手把手教程呈现：</h1><p>回顾一下相关性分析概念：相关性分析是指对两个或多个具备相关性的变量元素进行分析进而衡量两个变量因素的相关密切程度。相关性的元素之间需要存在一定的联系或者概率才可以进行相关性分析。相关性分析分为pearson相关分析、spearman相关性分析和kendall相关性分析。本次主要介绍Pearson相关分析。它适用于变量为连续性变量且变量之间存在线性关系的情况，二者缺一不可。</p><p>示例数据：来源于小鼠感染某种烈性病毒前后的转录组测序数据。实验设计为随机选择3只同一窝出生的小鼠，先提取血液进行转录组测序，随后同时向同窝小鼠注射某种烈性病毒，感染病毒第7天提取血液再进行转录组测序。拿到测序数据后跑完部分转录组分析流程，获取基因表达的reads计数结果。</p><p>在进行Pearson相关分析前，按照Pearson相关分析的基本要求先判断两个变量之间是否存在线性关系。随机选取同一个处理的两个生物学重复，用ggplot2绘制两个变量之间的散点图。</p><pre class=" language-R"><code class="language-R">library(ggplot2)ggplot(data = OUT883_withoutgenename[,1:2],mapping = aes(x=OUT883_withoutgenename[,1],y=OUT883_withoutgenename[,2],color="red"))+geom_point()+geom_smooth(method = lm) #geno_point()绘制散点图，geom_smooth()进行拟合，method选择lm是线性拟合</code></pre><p><img src="/img/correlation_analysis_in_R1.png" alt="correlation"><br>从上图可以看出，除去个别区间，两个变量主要呈现线性关系。之所以个别区间如x=0附近是这样的关系是由于我没有对数据进行过滤。（比如因为测序误差导致的在两个生物学重复之间由于测序仪误差一个基因在被测到而在对应生物学重复内没有测到）。</p><p>判断符合Pearson相关性分析条件后可以进行后续分析。现在要对这些数据进行两两相关性分析，以初步判断样本之间是否有较大差异。</p><pre class=" language-R"><code class="language-R">readscount<-read.table("病毒感染小鼠前后基因表达统计.txt",header=T,sep="\t")#读取数据GE_cormatrix<- matrix(ncol = ncol(readscount)-1,nrow = ncol(readscount)-1)#定义相关系数矩阵colnames(GE_cormatrix)=colnames(readscount[,2:ncol(readscount)])#定义相关系数矩阵列名rownames(GE_cormatrix)=colnames(readscount[,2:ncol(readscount)])#定义相关系数矩阵行名for(i in 1:ncol(GE_cormatrix)){  GE_cormatrix[i,i]<-1#任何一个样本与自身的相关性为1}readscount_withoutgenename<-readscount[,2:ncol(readscount)]#将读取的数据数值部分赋值给新矩阵readscount_withoutgenename<-readscount_withoutgenename[rowSums(readscount_withoutgenename)>1,]#过滤掉所有样本的基因表达都为0的行for(i in 1:(ncol(readscount_withoutgenename)-1)){  for(j in (i+1):ncol(readscount_withoutgenename)){    a<-readscount_withoutgenename[,i]    b<-readscount_withoutgenename[,j]    t<-cor.test(a,b,method = "pearson") #使用cor.test函数的Pearson模型计算相关系数    cor_num<-as.numeric(t$estimate) #将计算出的相关系数以数值形式传递给cor_num    GE_cormatrix[i,j]=cor_num #将相关性系数赋值给相关系数矩阵对于的位置    GE_cormatrix[j,i]=cor_num #由于相关系数矩阵是一个对称矩阵，其对称位置也为相同的相关系数  }}library(corrplot)corrplot(GE_cormatrix, type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)#使用corrplot函数可视化相关系数矩阵</code></pre><p><img src="/img/correlation_analysis_in_R2.png" alt="correlation matrix"></p><p>其中ABC指代小鼠感染病毒前的三个生物学重复样本，AD/BD/CD是感染病毒后安乐死的三个生物学重复，从图中结果看出，处理前的三个重复样本相关性高，处理后的三个样本相关性高。可以分别作为重复组进行下游分析。</p><h1 id="延伸讨论"><a href="#延伸讨论" class="headerlink" title="延伸讨论"></a>延伸讨论</h1><p>本例中有两个可拓展内容，一是本文介绍了三种相关系数计算方法，而作为教学目的只重点介绍了Person相关系数计算方法，另外两种相关系数Spearman和Kendall相关系数用于对分类变量的数据或变量值的分布明显非正态或分布不明时使用，计算时先对离散数据进行排序或对定距变量值排（求）秩。当然最好先通过作图柱状图或者散点图判断一下数据的分布是否属于正态分布，如果属于正态分布而且为连续型变量选择pearson即可，如果不属于就选择另外两个之一。本文中是对转录组基因表达定量的计算，基因表达可以看做正态分布。所以才选择的Pearson相关分析。另外本文的代码部分计算Pearson相关系数使用的函数是cor.test()函数，这个函数通常需要输入三个参数，即两个要计算相关关系的变量（无所谓前后，因为相关性分析只是判断两个变量是否相关），第三个参数是method，可以选择person、spearman、kendall。</p><h1 id="Take-Home-message"><a href="#Take-Home-message" class="headerlink" title="Take Home message"></a>Take Home message</h1><p>用R语言做重复相关性分析重点在于构建相关性矩阵然后利用corrplot函数可视化，要依据自身数据的统计学特点选择合理的相关性模型。<br><img src="/img/vazyme.png" alt="vazyme"></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>如何理解和计算FDR?</title>
      <link href="/2019/05/07/fdr/"/>
      <url>/2019/05/07/fdr/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>按照惯例，先来个自我介绍：</p><blockquote><p>大家好，我是实习6年的生信狗小明同学，不会唱、跳、Rap，喜欢装X，瞎逼逼和开车（话说我驾照都没啊），以后我将在这里给大家带来生信、统计学和机器学习方面的分享，希望大家能够喜欢（欢呼声和掌声现在可以起来了╭(●｀∀´●)╯）</p><p>最后给大家提供一个关注我的传送门：<code>https://ming-lian.github.io</code>，第一时间的更新在我的个人主页上，发到这里的都是在个人主页基础上的整理</p><p>爱你们哟｡:.ﾟヽ(｡◕‿◕｡)ﾉﾟ.:｡+ﾟ</p></blockquote><p>下面是正文</p><hr><h2 id="1-多重假设检验的必要性"><a href="#1-多重假设检验的必要性" class="headerlink" title="1. 多重假设检验的必要性"></a>1. 多重假设检验的必要性</h2><p>统计学中的假设检验的基本思路是：</p><blockquote><p>设立零假设（null hypothesis）$H_0$，以及与零假设$H_0$相对应的非零假设（alternative hypothesis， or reject null hypothesis）$H_1$，在假设$H_0$成立的前提下，计算出$H_0$发生的概率，若$H_0$的发生概率很低，基于小概率事件几乎不可能发生，所以可以拒绝零假设</p></blockquote><p>但是这些传统的假设检验方法研究的对象，都是一次试验</p><p>在一次试验中（注意：是一次试验， 即single test），0.05 或0.01的cutoff足够严格了(想象一下，一个口袋有100个球，95个白的，5个红的, 只让你摸一次，你能摸到红的可能性是多大？)</p><p>但是对于多次试验，又称多重假设检验，再使用p值是不恰当的，下面来分析一下为什么：</p><p>大家都知道墨菲定律：如果事情有变坏的可能，不管这种可能性有多小，它总会发生</p><p>用统计的语言去描述墨菲定律：</p><blockquote><p>在数理统计中，有一条重要的统计规律：假设某意外事件在一次实验（活动）中发生的概率为p（p&gt;0），则在n次实验（活动）中至少有一次发生的概率为 $p_n=1-(1-p)^n$</p><p>由此可见，无论概率p多么小（即小概率事件），当n越来越大时，$p_n$越来越接近1</p></blockquote><p>这和我们的一句俗语非常吻合：常在河边走，哪有不湿鞋；夜路走多了，总能碰见鬼</p><p>在多重假设检验中，我们一般关注的不再是每一次假设检验的准确性，而是控制在作出的多个统计推断中犯错误的概率，即False Discover Rate（FDR），这对于医院的诊断情景下尤其重要：</p><blockquote><p>假如有一种诊断艾滋病(AIDS)的试剂，试验验证其准确性为99%（每100次诊断就有一次false positive）。对于一个被检测的人（single test)）来说，这种准确性够了；但对于医院 （multiple test)）来说，这种准确性远远不够</p><p>因为每诊断10 000个个体，就会有100个人被误诊为艾滋病(AIDS)，每一个误诊就意味着一个潜在的医疗事故和医疗纠纷，对于一些大型医院，一两个月的某一项诊断的接诊数就能达到这个级别，如果按照这个误诊率，医院恐怕得关门，所以医院需要严格控制误诊的数量，宁可错杀一万也不能放过一个，因为把一个没病的病人误判为有病，总比把一个有病的病人误判为没病更保险一些</p></blockquote><ul><li><p>100 independent genes. (We have 100 hypotheses to test)</p></li><li><p>No significant differences in gene expression between 2 classes (H0 is true). Thus, the probability that a particular test (say, for gene 1) is declared significant at level 0.05 is exactly 0.05. (Probability of reject H0  in one test if H0 is true = 0.05)</p></li><li><p>However, the probability of declaring at least one of the 100 hypotheses false (i.e. rejecting at least one, or finding at least one result significant) is: </p></li></ul><p>$$1-(1-0.05)^{100}\approx 0.994$$</p><h2 id="2-区别p值和q值"><a href="#2-区别p值和q值" class="headerlink" title="2. 区别p值和q值"></a>2. 区别p值和q值</h2><table><thead><tr><th style="text-align:center"><code></code></th><th style="text-align:center">$H_0$ is true</th><th style="text-align:center">$H_1$ is true</th><th style="text-align:center">Total</th></tr></thead><tbody><tr><td style="text-align:center">Not Significant</td><td style="text-align:center">TN</td><td style="text-align:center">FN</td><td style="text-align:center">TN+FN</td></tr><tr><td style="text-align:center">Significant</td><td style="text-align:center">FP</td><td style="text-align:center">TP</td><td style="text-align:center">FP+TP</td></tr><tr><td style="text-align:center">Total</td><td style="text-align:center">TN+FP</td><td style="text-align:center">FN+TP</td><td style="text-align:center">m</td></tr></tbody></table><p>首先从上面的混淆矩阵来展示p值域q值的计算公式，就可以看出它们之间的区别：</p><blockquote><ul><li><p><strong>p值</strong></p><p> p值实际上就是false positive rate(FPR，假正率)：</p><p> $$p-value=FPR=\frac{FP}{FP+TN}$$</p><p> 直观来看，p值是用上面混淆矩阵的<strong>第一列</strong>算出来的</p></li><li><p><strong>q值</strong></p><p> q值实际上就是false discovery rate (FDR)：</p><p> $$q-value=FDR=\frac{FP}{FP+TP}$$</p><p> 直观来看，q值是用上面混淆矩阵的<strong>第二行</strong>算出来的</p></li></ul></blockquote><p>但是仅仅知道它俩的计算公式的差别还不够，我们还有必要搞清楚一个问题：它俩在统计学意义上有什么不同呢？</p><blockquote><p>p值衡量的是一个原本应该是$H_0$的判断被错误认为是$H_1 \, (reject H_0)$的比例，所以它是针对单次统计推断的一个置信度评估；</p><p>q值衡量的是在进行多次统计推断后，在所有被判定为显著性的结果里，有多大比例是误判的</p></blockquote><p>据此，我们可以推导出p值域q值（q值有两种定义，FWER或FDR，这里指的是FWER）之间的关系：</p><blockquote><p>总共有n个features(可以是基因，GWAS中的snp位点等)，对它们执行n重假设假设检验后，得到各自对应的p值分别为$\{p^{(i)} \mid i=1,2,…,n\}$</p><p>当p值显著性水平取$\alpha$时，得到$k$个features具有p值显著性，它们的p值为$\{p^{(i)}<em>{(j)} \mid j=1,2,…,k\}$，其中$p^{(i)}</em>{(j)}$表示第i个feature它的p值在升序中的排名为j，那么这k个features的FWER可以表示为：</p><p>$$FWER=1-\prod_{j=1}^{k}(1-p^{(i)}_{(j)})$$</p></blockquote><h2 id="3-如何计算q值？"><a href="#3-如何计算q值？" class="headerlink" title="3. 如何计算q值？"></a>3. 如何计算q值？</h2><p>统计检验的混淆矩阵：</p><table><thead><tr><th style="text-align:center"><code></code></th><th style="text-align:center">$H_0$ is true</th><th style="text-align:center">$H_1$ is true</th><th style="text-align:center">Total</th></tr></thead><tbody><tr><td style="text-align:center">Significant</td><td style="text-align:center">V</td><td style="text-align:center">S</td><td style="text-align:center">R</td></tr><tr><td style="text-align:center">Not Significant</td><td style="text-align:center">U</td><td style="text-align:center">T</td><td style="text-align:center">m-R</td></tr><tr><td style="text-align:center">Total</td><td style="text-align:center">m<sub>0</sub></td><td style="text-align:center">m-m<sub>0</sub></td><td style="text-align:center">m</td></tr></tbody></table><ul><li><p><strong>FWER (Family Wise Error Rate)</strong></p><p>  作出一个或多个假阳性判断的概率</p><p>  $$FWER=Pr(V\ge 1)$$</p><p>  使用这种方法的统计学过程：</p><ul><li>The Bonferroni procedure</li><li>Tukey’s procedure</li><li>Holm’s step-down procedure </li></ul></li><li><p><strong>FDR (False Discovery Rate)</strong></p><p>  在所有的单检验中作出假阳性判断比例的期望</p><p>  $$FDR=E\left[\frac{V}{R}\right]$$</p><p>  使用这种方法的统计学过程：</p><ul><li>Benjamini–Hochberg procedure</li><li>Benjamini–Hochberg–Yekutieli procedure</li></ul></li></ul><h3 id="3-1-Benjamini-Hochberg-procedure-BH"><a href="#3-1-Benjamini-Hochberg-procedure-BH" class="headerlink" title="3.1. Benjamini-Hochberg procedure (BH)"></a>3.1. Benjamini-Hochberg procedure (BH)</h3><p>对于m个独立的假设检验，它们的P-value分别为：$p_i,i=1,2,…,m$</p><p>（1）按照升序的方法对这些P-value进行排序，得到：</p><p>$$p_{(1)} \le p_{(2)} \le … \le p_{(m)}$$</p><p>（2）对于给定是统计显著性值$\alpha \in (0,1)$，找到最大的k，使得</p><p>$$p_{(k)} \le \frac{\alpha * k}{m}$$</p><p>（3）对于排序靠前的k个假设检验，认为它们是真阳性 (positive )</p><p>即：$reject \, H_0^{(i)},\, 1 \le i \le k$ </p><p>$$<br>\begin{array}{c|l}<br>\hline<br>Gene &amp; p-value \\<br>\hline<br>G1 &amp; P1 =0.053 \\<br>\hline<br>G2 &amp; P2 =0.001 \\<br>\hline<br>G3    &amp; P3 =0.045 \\<br>\hline<br>G4    &amp; P4 =0.03 \\<br>\hline<br>G5 &amp; P5 =0.02 \\<br>\hline<br>G6 &amp; P6 =0.01 \\<br>\hline<br>\end{array}<br>\, \Rightarrow \,<br>\begin{array}{c|l}<br>\hline<br>Gene &amp; p-value \\<br>\hline<br>G2    &amp; P(1) =0.001 \\<br>\hline<br>G6    &amp; P(2) =0.01 \\<br>\hline<br>G5    &amp; P(3) =0.02 \\<br>\hline<br>G4    &amp; P(4) =0.03 \\<br>\hline<br>G3    &amp; P(5) =0.045 \\<br>\hline<br>G1    &amp; P(6) =0.053 \\<br>\hline<br>\end{array}<br>$$</p><p><br></p><p>$$\alpha = 0.05$$</p><blockquote><p>$P(4) =0.03&lt;0.05*\frac46=0.033$</p><p>$P(5) =0.045&gt;0.05*\frac56=0.041$</p><p>因此最大的k为4，此时可以得出：在FDR&lt;0.05的情况下，G2，G6，G5 和 G4 存在差异表达</p></blockquote><p>可以计算出q-value：</p><p>$$p_{(k)} \le \frac{\alpha*k}{m} \, \Rightarrow \, \frac{p_{(k)}*m}{k} \le \alpha$$</p><p><br></p><table><thead><tr><th style="text-align:center">Gene</th><th style="text-align:left">P</th><th style="text-align:left">q-value</th></tr></thead><tbody><tr><td style="text-align:center">G2</td><td style="text-align:left">P(1) =0.001</td><td style="text-align:left">0.006</td></tr><tr><td style="text-align:center">G6</td><td style="text-align:left">P(2) =0.01</td><td style="text-align:left">0.03</td></tr><tr><td style="text-align:center">G5</td><td style="text-align:left">P(3) =0.02</td><td style="text-align:left">0.04</td></tr><tr><td style="text-align:center">G4</td><td style="text-align:left">P(4) =0.03</td><td style="text-align:left">0.045</td></tr><tr><td style="text-align:center">G3</td><td style="text-align:left">P(5) =0.045</td><td style="text-align:left">0.054</td></tr><tr><td style="text-align:center">G1</td><td style="text-align:left">P(6) =0.053</td><td style="text-align:left">0.053</td></tr></tbody></table><p>根据q-valuea的计算公式，我们可以很明显地看出：</p><p>$$q^{(i)}=p_{(k)}^{(i)}*\frac{Total \, Gene \, Number}{rank(p^{(i)})}=p_{(k)}^{(i)}*\frac{m}{k}$$</p><p>即，根据该基因p值的排序对它进行放大，越靠前放大的比例越大，越靠后放大的比例越小，排序最靠后的基因的p值不放大，等于它本身</p><p>我们也可以从可视化的角度来看待这个问题：</p><p>对于给定的$\alpha \in (0,1)$，设函数$y=\frac{\alpha}{m}x \quad (x=1,2,…,m)$，画出这条线，另外对于每个基因，它在图上的坐标为$(rank(p_{(k)}^{(i)}),p_{(k)}^{(i)})=(k,p_{(k)}^{(i)})$，图如下：</p><p><img src="/img/fdr.png" alt="correlation"></p><p>通过设置$\alpha$可以改变图中直线的斜率，$\alpha$越大，则直线的斜率越大，落在直线下方的点就越多，通过FDR检验的基因也就越多，反之，直线的斜率越小，落在直线下方的点就越少，通过FDR检验的基因也就越少</p><p>当固定$\alpha$，而统计检验次数m增加时，这条直线的斜率变小，落在直线下方的点就越少，通过FDR检验的基因也就越少</p><hr><p>参考资料：</p><p>(1) Storey, J.D. &amp; Tibshirani, R. Statistical signifcance for genomewide studies.Proc. Natl. Acad. Sci. USA 100, 9440–9445 (2003)</p><p>(2) 国科大研究生课程《生物信息学》，陈小伟《基因表达分析》</p><p><img src="/img/vazyme.png" alt="vazyme"></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NCBI Taxonomy数据处理：TaxonKit工具详解</title>
      <link href="/2019/04/22/taxonkit-usage/"/>
      <url>/2019/04/22/taxonkit-usage/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>原创：老板，来一打TPU</strong><br>    <div id="aplayer-BnGJgvkz" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="2786189" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div></p><h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>   在做宏基因组分析时，通过基因注释得到一个包含10k之多种微生物物种名list(scientific name)，现在想统计这些物种在界、门、纲、目、科、属等不同分类水平的总的数量。这就是本篇推送想解决的问题，10000多种微生物的拉丁名称示例如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>NeptuneYT$<span class="token punctuation">]</span> <span class="token function">head</span> scientific_name.txt</code></pre><blockquote><p>Abiotrophia defectiva<br>Abiotrophia sp.<br>Absiella dolichum<br>Acaryochloris marina<br>Acetanaerobacterium sp.<br>Acetivibrio cellulolyticus<br>Acetoanaerobium noterae<br>Acetoanaerobium sticklandii<br>Acetobacter aceti<br>Acetobacter ghanensis</p></blockquote><pre><code>[NeptuneYT$] wc -l all_bacteria_genomic_fna.species</code></pre><blockquote><p>10146 all_bacteria_genomic_fna.species</p></blockquote><p> 打开<a href="https://www.ncbi.nlm.nih.gov/taxonomy/" target="_blank" rel="noopener">NCBI Taxonomy</a>输入一个拉丁名，如Acetobacter aceti，搜索之后默认获得完整的lineage信息，但我们这里只需要7个层次的，因此再点击一次Lineage获得缩略的谱系信息，如下：<br><img src="/img/taxonkit_usage1.webp" alt="1"><br>得到的Lineage字段后以分号隔开的就是对应于7个分类层次的结果，后续以分号切割之后统计不同列的结果即可。<br>很自然的，我们想到爬虫，其搜索接口为:<br><a href="https://www.ncbi.nlm.nih.gov/taxonomy/?term=拉丁名（空格以+号连接），" target="_blank" rel="noopener">https://www.ncbi.nlm.nih.gov/taxonomy/?term=拉丁名（空格以+号连接），</a><br>如<a href="https://www.ncbi.nlm.nih.gov/taxonomy/?term=Acetobacter+aceti，" target="_blank" rel="noopener">https://www.ncbi.nlm.nih.gov/taxonomy/?term=Acetobacter+aceti，</a><br>然后对结果页面进行后续解析。<br>但是10k之多的查询量，必然要设置爬取频率，否则就要被NCBI关小黑屋了，考虑时间代价，果断放弃。其实，从网上查询的原理也是基于Taxonomy后台的数据库，而这个文件在<a href="ftp://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz，" target="_blank" rel="noopener">ftp://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz，</a><br>可以从解压之后的names.dmp和nodes.dmp文件写代码解析，但是其内容过于妖孽，为了少撸掉点头发，因此先看看网上是否有造好的轮子。<br><img src="/img/taxonkit_usage2.webp" alt="2"><br>果然，动动手指发现有三个工具可以实现以上诉求，ETE toolkit, taxadb和 TaxonKit，这里选择最近发表的TaxonKit，优势在于其直接基于names.dmp和nodes.dmp文件的解析，本地搜索速度块，尤其是大批量的查找和格式转换，另外使用也极简单。<br><img src="/img/taxonkit_usage3.webp" alt="3"><br><a href="http://dx.doi.org/10.1101/513523" target="_blank" rel="noopener">TaxonKit paper</a><br>相比于另外两种工具，TaxonKit在处理大批量数据时更快，占用内存也可接受</p><h2 id="taxonkit-概述"><a href="#taxonkit-概述" class="headerlink" title="taxonkit 概述"></a>taxonkit 概述</h2><p>说完废话，进入今天的主题，说说TaxonKit这个工具的使用。<br>TaxonKit是处理NCBI Taxonomy数据库中结构性数据的良心工具，19年1月在bioRxiv上online，作者Wei Shen, Jie Xiong，隶属于Department of ClinicalLaboratory, General Hospital of Western Theater Command，特地查了一下，原来是位于成都的中国人民解放军西部战区总医院（好牛的感觉），看来生信真是无处不在。<br><img src="/img/taxonkit_usage4.webp" alt="4"><br>它是Go语言编写的，可以在Windows，Linux和Mac OS X运行，直接使用NCBI Taxonomy的数据（需手动下载）而无需构建本地数据库。</p><h2 id="taxonkit安装"><a href="#taxonkit安装" class="headerlink" title="taxonkit安装"></a>taxonkit安装</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>选择对应系统的版本安装，推荐conda安装。详见<a href="https://github.com/shenwei356/taxonkit" target="_blank" rel="noopener">https://github.com/shenwei356/taxonkit</a>,<br>conda安装:<br>conda install -c bioconda taxonkit</p><h3 id="下载依赖数据"><a href="#下载依赖数据" class="headerlink" title="下载依赖数据"></a>下载依赖数据</h3><p>下载NCBI taxonomy数据库的taxdump.tar.gz文件，解压后将names.dmp和 nodes.dmp拷贝到家目录下的.taxonkit目录下。</p><pre class=" language-bash"><code class="language-bash"><span class="token function">wget</span> -c ftp://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz <span class="token function">tar</span> -zxvf taxdump.tar.gz<span class="token function">mkdir</span> -p <span class="token variable">$HOME</span>/.taxonkit<span class="token function">cp</span> names.dmp nodes.dmp <span class="token variable">$HOME</span>/.taxonkit</code></pre><p>确认文件完整：</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>NeptuneYT<span class="token punctuation">]</span>$ ll -h  ~/.taxonkit/</code></pre><blockquote><p>total 155494<br>-rw-r–r–    1 xx    UsersGrp  169.3M Mar 18 16:07 names.dmp<br>-rw-r–r–    1 xx    UsersGrp  134.4M Mar 18 16:07 nodes.dmp</p></blockquote><p>配置完成，开始使用。</p><h2 id="taonkit使用"><a href="#taonkit使用" class="headerlink" title="taonkit使用"></a>taonkit使用</h2><p>taxonkit –help</p><blockquote><p>Usage:<br>  taxonkit [command]<br>  Available Commands:<br>  genautocomplete generate shell autocompletion script<br>  help            Help about any command<br>  lineage         query lineage of given taxids<br>  list            list taxon tree of given taxids<br>  name2taxid      query taxid by taxon scientific name<br>  reformat        reformat lineage<br>  version         print version information and check for update<br>…<br>Use “taxonkit [command] –help” for more information about a command.</p></blockquote><p>taxonkit按照功能分成不同的子命令，其中最主要的功能包括4块：<br>1）列出给定taxonomy id(taxid)的子分类树：list<br>2）从taxid获取完整谱系：lineage<br>3）重新构造谱系的格式：reformat<br>4）通过物种拉丁名查询taxid：name2taxid</p><h3 id="1）列出给定taxonomy-id的子分类树"><a href="#1）列出给定taxonomy-id的子分类树" class="headerlink" title="1）列出给定taxonomy id的子分类树"></a>1）列出给定taxonomy id的子分类树</h3><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>NeptuneYT$<span class="token punctuation">]</span> taxonkit list --help   <span class="token comment" spellcheck="true">#查看list子命令使用方法</span></code></pre><blockquote><p>list taxon tree of given taxids<br>Usage:<br>  taxonkit list [flags]<br>Flags:<br>  -h, –help            help for list<br>      –ids string      taxid(s), multiple values should be separated by comma<br>      –indent string   indent (default “  “)<br>      –json            output in JSON format. you can save the result in file with suffix “.json” and open with modern text editor<br>      –show-name       output scientific name<br>      –show-rank       output rank<br>Global Flags:<br>      –data-dir string   directory containing nodes.dmp and names.dmp (default “/home/xx/.taxonkit”)<br>      –line-buffered     use line buffering on output, i.e., immediately writing to stdin/file for every line of output<br>  -o, –out-file string   out file (“-“ for stdout, suffix .gz for gzipped out) (default “-“)<br>  -j, –threads int       number of CPUs. (default value: 1 for single-CPU PC, 2 for others) (default 2)<br>      –verbose           print verbose information</p></blockquote><p>实例：<br>给定taxid：9606和10090</p><pre><code>[NeptuneYT$] taxonkit list --ids 9606,10090 --show-name  --show-rank -j 2</code></pre><p> #–ids 给定的taxid，多个以英文逗号分割</p><p> #–show-name    输出科学命名</p><p> #–show-rank    输出分类等级</p><p> #-j 线程数，默认是2</p><blockquote><p>9606 [species] Homo sapiens<br>  63221 [subspecies] Homo sapiens neanderthalensis<br>  741158 [subspecies] Homo sapiens subsp. ‘Denisova’</p></blockquote><blockquote><p>10090 [species] Mus musculus<br>  10091 [subspecies] Mus musculus castaneus<br>  10092 [subspecies] Mus musculus domesticus<br>  35531 [subspecies] Mus musculus bactrianus<br>  39442 [subspecies] Mus musculus musculus<br>  46456 [subspecies] Mus musculus wagneri<br>  57486 [subspecies] Mus musculus molossinus<br>  80274 [subspecies] Mus musculus gentilulus<br>  116058 [subspecies] Mus musculus brevirostris<br>  179238 [subspecies] Mus musculus homourus<br>  477815 [subspecies] Mus musculus musculus x M. m. domesticus<br>  477816 [subspecies] Mus musculus musculus x M. m. castaneus<br>  947985 [subspecies] Mus musculus albula<br>  1266728 [subspecies] Mus musculus domesticus x M. m. molossinus<br>  1385377 [subspecies] Mus musculus gansuensis<br>  1643390 [subspecies] Mus musculus helgolandicus<br>  1879032 [subspecies] Mus musculus isatissus</p></blockquote><h3 id="2）从taxid获取完整谱系"><a href="#2）从taxid获取完整谱系" class="headerlink" title="2）从taxid获取完整谱系"></a>2）从taxid获取完整谱系</h3><pre><code>[NeptuneYT$] echo 9606|taxonkit lineage  -d &quot;-&quot; -t -r</code></pre><p> #-d 输出谱系树分割符，默认分号</p><p> #-t 显示包含taxid的谱系树</p><p> #-r 显示给定taxid的分类等级</p><blockquote><p>9606    cellular organisms-Eukaryota-Opisthokonta-Metazoa-Eumetazoa-Bilateria-Deuterostomia-Chordata-Craniata-Vertebrata-Gnathostomata-Teleostomi-Euteleostomi-Sarcopterygii-Dipnotetrapodomorpha-Tetrapoda-Amniota-Mammalia-Theria-Eutheria-Boreoeutheria-Euarchontoglires-Primates-Haplorrhini-Simiiformes-Catarrhini-Hominoidea-Hominidae-Homininae-Homo-Homo sapiens      131567-2759-33154-33208-6072-33213-33511-7711-89593-7742-7776-117570-117571-8287-1338369-32523-32524-40674-32525-9347-1437010-314146-9443-376913-314293-9526-314295-9604-207598-9605-9606   species</p></blockquote><h3 id="3）重新构造谱系的格式"><a href="#3）重新构造谱系的格式" class="headerlink" title="3）重新构造谱系的格式"></a>3）重新构造谱系的格式</h3><p>上一步通过taxid提取的谱系信息复杂，往往需要根据我们的需求重新格式化</p><pre><code>[NeptuneYT$] echo 9606|taxonkit lineage |taxonkit reformat</code></pre><blockquote><p>9606    cellular organisms;Eukaryota;Opisthokonta;Metazoa;Eumetazoa;Bilateria;Deuterostomia;Chordata;<br>Craniata;Vertebrata;Gnathostomata;Teleostomi;Euteleostomi;Sarcopterygii;Dipnotetrapodomorpha;Tetrapoda;<br>Amniota;Mammalia;Theria;Eutheria;Boreoeutheria;Euarchontoglires;Primates;Haplorrhini;Simiiformes;<br>Catarrhini;Hominoidea;Hominidae;Homininae;Homo;Homo sapiens<br>Eukaryota;Chordata;Mammalia;Primates;Hominidae;Homo;Homo sapiens</p></blockquote><p>输出结果的第三列就是重新格式化的结果，默认是(“{k};{p};{c};{o};{f};{g};{s}”)7个水平。<br>查询给定taxid9606的谱系，并按照门：科；属的格式输出</p><pre><code>[NeptuneYT$] echo 9606|taxonkit lineage |taxonkit reformat -f &quot;{p}:{f};{s}&quot; |cut -f3</code></pre><p> #{}内是分类等级，大括号之间是输出的连接符</p><blockquote><p>Chordata:Hominidae;Homo sapiens</p></blockquote><h3 id="4）通过物种拉丁名查询taxid：name2taxid"><a href="#4）通过物种拉丁名查询taxid：name2taxid" class="headerlink" title="4）通过物种拉丁名查询taxid：name2taxid"></a>4）通过物种拉丁名查询taxid：name2taxid</h3><p>按人的拉丁名查询taxid</p><pre><code>[NeptuneYT$] echo &quot;Homo sapiens&quot; |taxonkit name2taxid</code></pre><blockquote><p>Homo sapiens    9606<br>批量查询</p><pre><code>[NeptuneYT$] head scientific_name.txt |taxonkit name2taxid --show-rank</code></pre><p>Abiotrophia defectiva   46125   species<br>Abiotrophia sp. 76631   species<br>Absiella dolichum       31971   species<br>Acaryochloris marina    155978  species<br>Acetanaerobacterium sp.<br>Acetivibrio cellulolyticus      35830   species<br>Acetoanaerobium noterae 745369  species<br>Acetoanaerobium sticklandii     1511    species<br>Acetobacter aceti       435     species<br>Acetobacter ghanensis   431306  species</p></blockquote><h2 id="回到问题"><a href="#回到问题" class="headerlink" title="回到问题"></a>回到问题</h2><p>基于Taxonkit上述用法，回到之前的问题就好解决了<br>1.将scientific name先转化成taxid，便于查找lineage</p><pre class=" language-bash"><code class="language-bash"><span class="token function">time</span> taxonkit name2taxid  scientific_name.txt <span class="token operator">></span>scientific_name_taxid.txt <span class="token operator">&amp;</span><span class="token function">awk</span> -F<span class="token string">"\t"</span> <span class="token string">'<span class="token variable">$2!</span>=""{print <span class="token variable">$2</span>}'</span>  scientific_name.txt <span class="token operator">></span>find_taxid.txt  <span class="token comment" spellcheck="true">#去掉未查到的，即空值</span><span class="token function">awk</span> -F<span class="token string">"\t"</span> <span class="token string">'<span class="token variable">$2</span>==""'</span>  scientific_name_taxid.txt <span class="token operator">></span>NotFindName.txt <span class="token comment" spellcheck="true">#输出未查到物种名</span><span class="token function">awk</span> -F<span class="token string">"\t"</span> <span class="token string">'BEGIN{OFS="\t";print "findTaxid\tNull\tTotal"}{<span class="token variable">$2!</span>=""?taxid++:null++}\END{print taxid,null,taxid+null}'</span> scientific_name_taxid.txt <span class="token operator">|</span>column -t <span class="token comment" spellcheck="true">#统计查找到的和未查到的数量</span></code></pre><blockquote><p>real    0m6.279s<br>findTaxid  Null  Total<br>9606       541   10147</p></blockquote><p>可以看到，查询速度相当之快。<br>由于待批量查询的物种名不是规范的拉丁名称，导致出现两个问题，一是输入的list是10146个,转换id后（找到和未找到）的行数却增加了1个，统计之后发现是同一个物种名有两个taxid；二是没找到的高达541个！！！为了说明完整的处理过程，541个后面再说。</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>NeptuneYT$<span class="token punctuation">]</span>$ <span class="token function">awk</span> -F<span class="token string">"\t"</span> <span class="token string">'{print <span class="token variable">$1</span>}'</span> scientific_name_taxid.txt <span class="token operator">|</span><span class="token function">sort</span> <span class="token operator">|</span><span class="token function">uniq</span> -d    </code></pre><blockquote><p>Deinococcus soli</p></blockquote><p>手工查询发现是两个种，但是根据部分拉丁名Deinococcus soli可以查到俩taxid我也是醉了。<br><img src="/img/taxonkit_usage5.webp" alt="7"><br>2.查找lineage</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>NeptuneYT$<span class="token punctuation">]</span> <span class="token function">time</span> taxonkit lineage find_taxid.txt <span class="token operator">></span>lineage.txt<span class="token operator">&amp;</span></code></pre><blockquote><p>real    0m7.860s</p></blockquote><p>3.重新格式化lineage</p><pre><code>[NeptuneYT$] time taxonkit reformat lineage.txt|cut -f3 &gt;newformat.txt&amp;</code></pre><blockquote><p>real    0m11.465s</p></blockquote><p>结果：<br><img src="/img/taxonkit_usage6.webp" alt="1"><br>现在就按照界门纲目科属种的层次变成整齐划一的格式了，通过简单处理即可统计不同层次的物种数量和分布，首先构建一个用于循环处理的分类标签</p><pre><code>[NeptuneYT$] cat tag.txt</code></pre><blockquote><p>1 Kingdom<br>2 Phylum<br>3 Class<br>4 Order<br>5 Family<br>6 Genus<br>7 Species</p></blockquote><p>详细的物种分类层次数量统计：</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>NeptuneYT$<span class="token punctuation">]</span> <span class="token function">cat</span> tag.txt<span class="token operator">|</span><span class="token keyword">while</span> <span class="token function">read</span> num lev<span class="token punctuation">;</span><span class="token keyword">do</span>  <span class="token function">awk</span> -v v<span class="token operator">=</span><span class="token variable">$num</span> -F<span class="token string">";"</span> <span class="token string">'{print <span class="token variable">$v</span>}'</span> newformat.txt<span class="token operator">|</span><span class="token function">sort</span> <span class="token operator">|</span><span class="token function">uniq</span> -c<span class="token operator">|</span><span class="token function">sort</span> -nr <span class="token operator">|</span><span class="token function">awk</span> -v v<span class="token operator">=</span><span class="token variable">$lev</span> <span class="token string">'{print v"\t"<span class="token variable">$0</span>}'</span> \<span class="token operator">|</span><span class="token function">awk</span> <span class="token string">'<span class="token variable">$3!</span>=""'</span><span class="token punctuation">;</span><span class="token keyword">done</span> <span class="token operator">></span>detail_taxonomy_range.txt<span class="token punctuation">[</span>NeptuneYT$<span class="token punctuation">]</span> <span class="token function">head</span> detail_taxonomy_range.txt</code></pre><blockquote><p>Kingdom       6722 Bacteria<br>Kingdom             4 Eukaryota<br>Phylum          2682 Proteobacteria<br>Phylum         1390 Firmicutes<br>Phylum         1099 Actinobacteria<br>Phylum          729 Bacteroidetes</p></blockquote><p>按7个类别统计数量：</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>NeptuneYT$<span class="token punctuation">]</span> <span class="token function">cat</span> tag.txt<span class="token operator">|</span><span class="token keyword">while</span> <span class="token function">read</span> index level<span class="token punctuation">;</span><span class="token keyword">do</span> num<span class="token operator">=</span><span class="token punctuation">$(</span>awk -v v<span class="token operator">=</span><span class="token variable">$index</span> -F<span class="token string">";"</span> <span class="token string">'{print <span class="token variable">$v</span>}'</span> \newformat.txt<span class="token operator">|</span><span class="token function">sort</span> <span class="token operator">|</span><span class="token function">uniq</span> <span class="token operator">|</span><span class="token function">wc</span> -l<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">printf</span>  <span class="token string">"<span class="token variable">${level}</span>\t<span class="token variable">${num}</span>\n"</span><span class="token punctuation">;</span><span class="token keyword">done</span> <span class="token operator">|</span><span class="token function">tee</span> taxonomy_stat.txt</code></pre><blockquote><p>Kingdom      2<br>Phylum       118<br>Class     82<br>Order      181<br>Family      401<br>Genus       1824<br>Species      6519</p></blockquote><p>简单画个图瞅瞅：</p><pre class=" language-R"><code class="language-R">data<-read.table('taxonomy_stat.txt')library('ggplot2')ggplot(data,aes(reorder(V1,-V2),V2,fill=V1))+geom_bar(stat='identity')+xlab('Taxonomy level')\+ylab('Numbers')+geom_text(aes(label=V2),position=position_dodge(.9),vjust=-1.5)+theme(text=\element_text(size=16,family='Times New Roman',face='bold'))+labs(fill='level')</code></pre><p><img src="/img/taxonkit_usage7.webp" alt="1"> </p><h2 id="一个也不能少"><a href="#一个也不能少" class="headerlink" title="一个也不能少"></a>一个也不能少</h2><p>首先看看没有找到的541个输入物种名长啥样：</p><blockquote><p>Bacillus sp.<br>[Bacillus thuringiensis]<br>bacteria symbiont<br>Bacteriovorax sp.<br>bacterium 42 11<br>bacterium BRH c32<br>bacterium Candidatus<br>bacterium CG06 land 8 20 14 3 00 33 50<br>bacterium CG09 39 24<br>bacterium CG1 02 42 9<br>…</p></blockquote><p>这个物种list是师妹们给的，实在太好（yao）看(nie)可了，拷问了一遍奈何就只有这样的查询list，那就只能手工挑了几个去网页上查了，发现没有找到taxid的原因包括：<br>1）出现多个搜索结果：原物种名Acaryochloris sp.，搜到的拉丁名：Acaryochloris sp. A4cAcaryochloris marinaAsterochloris sp. DA2Asterochloris sp. 101Asterochloris sp. 103<br>2）截短名称：原物种名Acetothermia bacterium，搜到结果：Candidatus Acetothermia bacterium<br>3）多加中括号：[Bacillus thuringiensis]<br>4）没有下划线：bacterium 42 11，搜到结果：bacterium 42_11<br>针对多加中括号和没有下划线的问题，可以先处理一下，其他的就只能手工查了。</p><pre class=" language-bash"><code class="language-bash"><span class="token function">sed</span> -e <span class="token string">"s/\[//g;s/\]//g"</span>   NotFindName.txt <span class="token operator">></span>bracket_minus_name.txt <span class="token comment" spellcheck="true">#minus all bracket</span><span class="token function">awk</span> <span class="token string">'{filed1=<span class="token variable">$1</span>;<span class="token variable">$1</span>="";sub(/ /,"");gsub(/ /,"_");print filed1,<span class="token variable">$0</span>}'</span>\NotFindName.txt  <span class="token operator">></span>underline_plus_name.txt <span class="token comment" spellcheck="true">#plus all filed of split underline except first one</span></code></pre><p>将后面查到的taxid加到之前的taxid list再按之前的流程跑一遍即可，实在查不到的那就手工吧。（此时配乐起~“这是自由的感觉，鼠标咔哒咔哒点击这些可爱的物种名称，<br>凭着一颗永不哭泣勇敢的心”）</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://github.com/shenwei356/taxonkit" target="_blank" rel="noopener">taxonkit github</a><br><a href="http://dx.doi.org/10.1101/513523" target="_blank" rel="noopener">TaxonKit: a cross-platform and efficient NCBI taxonomy toolkit</a><br><img src="/img/vazyme.png" alt="vazyme"></p>]]></content>
      
      
      <categories>
          
          <category> Bioinformatics </category>
          
      </categories>
      
      
        <tags>
            
            <tag> taxonkit </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>source/about/about.md</title>
      <link href="/2019/04/19/source-about-about-md/"/>
      <url>/2019/04/19/source-about-about-md/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>来吧，让我们相爱吧--硬核推送</title>
      <link href="/2019/04/10/push-us/"/>
      <url>/2019/04/10/push-us/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>    <div id="aplayer-egwTMajH" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="26989255" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><p><strong>原创: 伊颜落芸 宇宙实验媛</strong></p><h1 id="友情公众号推送"><a href="#友情公众号推送" class="headerlink" title="友情公众号推送"></a>友情公众号推送</h1><p>​     一直关注我们<a href="https://mp.weixin.qq.com/mp/profile_ext?action=home&amp;__biz=MzAxMDkxODM1Ng==&amp;scene=124#wechat_redirect" target="_blank" rel="noopener">生信技能树</a>公众号的小伙伴肯定知道，我们一向的原则是分享学习心得，提供知识的干货。所以今天就向大友情家推荐一个亲民又有料的公众号—<strong>宇宙实验媛</strong>。</p><h2 id="生信技能树-amp-宇宙实验媛"><a href="#生信技能树-amp-宇宙实验媛" class="headerlink" title="生信技能树  &amp;  宇宙实验媛"></a>生信技能树  &amp;  宇宙实验媛</h2><pre class=" language-python"><code class="language-python">十年同窗，五年同行。因生信而结缘，因科学而励志</code></pre><p>我们的创始人Jimmy和宇宙实验媛的主编yuzy是大学同学，都说妇女能顶半边天，yuzy既然喊出了豪言壮语，那小编不得不推荐一下了😜<br><a id="more"></a></p><h2 id="关于“宇宙实验媛”"><a href="#关于“宇宙实验媛”" class="headerlink" title="关于“宇宙实验媛”"></a>关于“宇宙实验媛”</h2><p>​    一听这个名字就很霸气😲，这个公众号的重点分享基因组学实验操作和生物信息学方法，但也关注优秀文献的分享，实用方法的解读，理论模型的创新。立足于全方位多角度揭示科学的故事。</p><p><strong>下面是该公众号的往期精选</strong></p><hr><h2 id="模式动物选择："><a href="#模式动物选择：" class="headerlink" title="模式动物选择："></a>模式动物选择：</h2><p>​    <a href="https://mp.weixin.qq.com/s/ukrfQ89EmQqPcF5zcjniWQ" target="_blank" rel="noopener">微生物组学研究的那些奇葩动物学模型</a> 介绍了研究终极目标—明确三种关系：生境内各微生物之间的关系；微生物与物质代谢/物质循环的关系；微生物与生境（比如宿主内）稳态的关系 所进行的差异性模型选择。</p><p><img src="/img/微生物组学动物选择.jpg" alt="微生物组学动物选择">​    </p><hr><h2 id="实用论文投稿及发表技巧"><a href="#实用论文投稿及发表技巧" class="headerlink" title="实用论文投稿及发表技巧"></a>实用论文投稿及发表技巧</h2><p>​    <a href="https://mp.weixin.qq.com/s/e-CVd1tR-HvIdjKwlUsxpQ" target="_blank" rel="noopener">浅谈期刊投稿与论文发表（上）</a> 分享了如何进行目标期刊的筛选和规避投稿的雷区；<a href="https://mp.weixin.qq.com/s/ekNtDZTSg8nF0TmI-CUFEw" target="_blank" rel="noopener">浅谈期刊投稿与论文发表（下）</a> 结合笔者自身经历讲述何为“行百里者半九十”。</p><p><img src="/img/期刊投稿与文献筛选.jpg" alt="投稿-1"></p><hr><h2 id="复杂计算模型及概念"><a href="#复杂计算模型及概念" class="headerlink" title="复杂计算模型及概念"></a>复杂计算模型及概念</h2><p>​    如果你对机器学习和经典的数据模型感兴趣，你可以看看<a href="https://mp.weixin.qq.com/s/yQMLyugLJAwoCHHAjbLVfA" target="_blank" rel="noopener">机器学习数据分析极简思路及sklearn算法实践小试</a> </p><p><img src="/img/机器学习-1.png" alt="机器学习-1"><br><img src="/img/机器学习-2.jpg" alt="机器学习-2"></p><hr><h2 id="实用数据挖掘"><a href="#实用数据挖掘" class="headerlink" title="实用数据挖掘"></a>实用数据挖掘</h2><p>​    没有实验思路和线索怎么办？没关系，看看这些或许能给你一点思路：</p><p><a href="https://mp.weixin.qq.com/s/AOWsR_zXxU_QAmkY_feCmw" target="_blank" rel="noopener">基于组学数据的分子功能挖掘</a></p><p><a href="https://mp.weixin.qq.com/s/EFSAIKhd4WT24M8rrXqtrg" target="_blank" rel="noopener">骨肉瘤中发现DANCR作为ceRNA促进增殖和转移</a></p><p><img src="/img/数据挖掘.jpg" alt="数据挖掘"></p><hr><h2 id="优秀文献赏析"><a href="#优秀文献赏析" class="headerlink" title="优秀文献赏析"></a>优秀文献赏析</h2><p>​    <a href="https://mp.weixin.qq.com/s/_r7uTJck9wvYnCaUKWQVjQ" target="_blank" rel="noopener">“单细胞”中研究调控细胞周期起始的分子机制</a> 深度剖析细胞周期研究的精细调控机制，<a href="https://mp.weixin.qq.com/s/zRVukdpUpJq9gvCkXqXYXA" target="_blank" rel="noopener">明星分子非经典功能研究与组学数据挖掘的结合</a> 紧跟热点研究方向，挖掘多组学平台对经典生物学分子的功能研究。</p><p><img src="/img/单细胞细胞周期.jpg" alt="单细胞细胞周期"></p><hr><h2 id="生物实验狗最关心的详细实验技巧"><a href="#生物实验狗最关心的详细实验技巧" class="headerlink" title="生物实验狗最关心的详细实验技巧"></a>生物实验狗最关心的详细实验技巧</h2><p><a href="https://mp.weixin.qq.com/s/w7ynqJS8RUBfRvlpuODekw" target="_blank" rel="noopener">CHIP-Seq经验总结</a> 为你保驾护航，<a href="https://mp.weixin.qq.com/s/82bT95qecXMmVJ23CFOtng" target="_blank" rel="noopener">Western Blot详细攻略</a> 让你显影的时候不再如履薄冰。</p><p><img src="/img/CHIP-Seq.jpg" alt="CHIP-Seq"></p><hr><h2 id="非主流的快乐"><a href="#非主流的快乐" class="headerlink" title="非主流的快乐"></a>非主流的快乐</h2><p>运营这个公众号的小伙伴是一群对科学有兴趣的年轻人，他们不光分享干货还创造快乐，比如偶尔皮一下的编辑们，画风是这样的。。。。。。</p><p><img src="/img/非正式-01.jpg" alt="非正式-01"></p><p><img src="/img/非正式-02.jpg" alt="非正式-02"></p><hr><p>​    上面的介绍如果让你心动就赶紧关注起来吧～</p><p><img src="/img/推荐关注.jpg" alt="推荐关注"></p>]]></content>
      
      
      <categories>
          
          <category> We </category>
          
          <category> Photo </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅说动力学模型（上篇）</title>
      <link href="/2019/04/09/dynamic-model1/"/>
      <url>/2019/04/09/dynamic-model1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script>    <div id="aplayer-LZgFFpXY" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="26989255" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><p><strong>原创： 赵洪龙 宇宙实验媛</strong> </p><h1 id="插曲"><a href="#插曲" class="headerlink" title="插曲"></a>插曲</h1><p><strong>以前我还在中科院-马普学会计算生物学伙伴研究所的时候，常常有朋友问我诸如“会不会做DNA数据分析？”，“会不会做甲基化数据分析？”之类的生物信息学（狭义）问题。很惭愧，我没有这方面的经验。又有朋友觉得奇怪， 追问：“你不做实验，又不做生物信息学分析，那你到底是干什么的？”我是做动力学模型的。“什么模型？”基于常微分方程的动力学模型，是动力学模型中的一种。每次说到这里，对方的反应总是一愣，随后一蒙，然后一呵呵。这里，我就来简单说说动力学模型到底是个什么东西。</strong><br><img src="/img/dynamic1_1.webp" alt="01"><br><a id="more"></a></p><h1 id="关于模型的简介"><a href="#关于模型的简介" class="headerlink" title="关于模型的简介"></a>关于模型的简介</h1><p>说到模型，很多人首先就是一哆嗦，因为想到了一堆符号公式和复杂的拓扑结构图形等等。其实大可不必紧张，模型实际上就是我们对客观世界认知和归纳的一个抽象体。就像我们买房子的时候，售楼小姐姐和小哥哥给我们展示的小区规划图、等比缩放沙盘一样，这些都是模型。地产商只是把一些我们想了解的楼盘信息抽象出来，用图画或者微缩造型的形式呈现在我们面前，再或者直接用语言表达：这个楼背靠青山，那个楼面朝大海。这些模型能告诉我们哪些楼有哪些特点，让我们不用亲临现场就能明白住进去后的基本感受。<br>同样地，科学家们说是在研究自然，实际上大部分的工作都是在观察，以及建立模型来描述研究对象，最后再基于模型的研究结果去改造这个世界。而那些带有令人望而生畏的符号和公式的数学模型与生物学中心法则的描述的差别在于，前者用的是数学语言，后者用的是自然语言。<br>要了解数学模型，首先就要了解其基本的功能：<strong>第一，整合信息</strong>，根据所研究的问题综合现有的信息对研究对象进行系统地描述。<strong>第二，预测</strong>，通过对模型中的参数和环境条件的扰动可预测系统在宏观层面的表现和变化。<strong>第三，提出可验证的假说</strong>。<br><img src="/img/dynamic1_2.webp" alt="35800716e266902e4fe68ab558d981fb.gif"></p><h1 id="模型在生物学研究中的必要性"><a href="#模型在生物学研究中的必要性" class="headerlink" title="模型在生物学研究中的必要性"></a>模型在生物学研究中的必要性</h1><p>经过过去几百年的观察和研究，人类越来越意识到生物学系统的复杂性。由于技术和资源的限制，大量的研究都是局限于特定过程的离散的研究。这些离散的研究让我们获得了对特定生命过程的了解，并建立了生物学模型。然而，在实际的生命体中，这些生命过程往往相互联系并交织成一张极为复杂的网络，很多现象并不能直观地根据已有的法则和原理所解释，也不能根据经验进行可靠地预测。即使现在我们能够轻易获得海量的组学数据，但是当面对如此复杂的网络时，我们也几乎无法对其进行人为的归纳和演绎。因此，数学建模结合计算机模拟应运而生。<strong>它们能够整合这些网络中的主要原件和内在互作过程进行模拟仿真，从而帮助我们理解复杂网络中的扰动对系统表现的影响</strong>。通过这样的方式，我们知道了，生命过程是遵循一些共性或者说是规律而自发涌现出来的一种状态。</p><h1 id="模型构建的原则和方法"><a href="#模型构建的原则和方法" class="headerlink" title="模型构建的原则和方法"></a>模型构建的原则和方法</h1><p>数学模型包括两个基本要素：<strong>结构和参数</strong>。说白了，结构就是关系，就是所研究的问题中包含的要素（转录因子，基因，酶等等）和要素之间的相互作用与联系（如化学计量学比例，事件发生先后，调控等等）。而每一种要素的状态变化及其相互作用都需要用数学表达式来描述。建模的具体步骤如图1所示。<br><img src="/img/dynamic1_3.webp" alt="35800716e266902e4fe68ab558d981fb.gif"><br>图1. 数学建模的关键步骤下面将通过一个简单的例子来说明建模的必要性和过程（本例子也许不是最合适的，但却能够简单描述建模的过程及意义）：<br><strong>（1）确立研究目标</strong>：A同学研究一个酶促反应的反应特征，并希望通过构建反应速率与底物浓度之间的模型，利用模型预测来指导工程改造酶的特征，以更好地得到产物B。</p><pre class=" language-math"><code class="language-math">S→B</code></pre><p><strong>（2）收集信息</strong>：根据前人研究发现，该反应服从米氏动力学特征的不可逆反应。故可以用米氏动力学方程来描述这个反应过程。并且文献记载该酶的最大催化速率V1为2，米氏常数Km1为2。<br><strong>（3）建立模型</strong>：</p><pre class=" language-math"><code class="language-math">v=V*[S]/(Km+[S] )</code></pre><p>其中，[S]表示底物浓度；V表示目标酶在特定条件下的最大催化速率；Km表示米氏常数（最大反应速率一半时底物的浓度）；v表示因变量，即在底物S的浓度为[S]时对应的实际反应速率。<br><strong>（4）模型的参数化及验证</strong>：将V1 = 2，Km1 = 2作为参数输入模型，在所有浓度范围内，均可计算出该反应的实际反应速率（图2蓝线所示）。并且文献查找获得了一系列底物浓度条件下该反应的反应速率数据（图2中黑色实心点）。<br><strong>（5）模型预测并提出假设</strong>：通过改变模型中参数V和Km比较反应速率与底物浓度之间的关系，发现改变V时改变了该反应的最大催化能力，而改变Km时改变了催化过程对底物的敏感度。提出假设：在底物浓度高的反应器中需要增加该酶的量，而在反应物浓度比较低的反应器中需要改变酶对底物的敏感性！<br>（6）<strong>用实验构建</strong>分别改变V和Km的酶，测量底物与反应速率之间的关系，如果能和预测结果吻合，说明该模型对于需要研究的目标问题具有一定的预测能力，并且用于实际的化工合成或者生物合成；否则，需要重新建模或者补充信息，直至能吻合为止。<br><img src="/img/dynamic1_4.webp" alt="04"><br>图2. 反应速率与反应物S的浓度在不同特征酶催化条件下的关系。图中的蓝线表示当前条件下模型模拟的关系趋势线，其余的线条表示模型预测改变酶特征后可能的关系；黑色实心圆点表示实验测量在当前酶特征条件下，不同底物浓度时对应的反应速率；彩色实心椭圆点表示改造后最大反应速率的一半以及对应的底物所需浓度。<br><img src="/img/vazyme.png" alt="vazyme"><br><a href="http://m.vazyme.com/Home.html" target="_blank" rel="noopener">南京诺维赞南京诺唯赞生物科技有限公司</a></p>]]></content>
      
      
      <categories>
          
          <category> Bio Cooking </category>
          
      </categories>
      
      
        <tags>
            
            <tag> dynamic model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ChIP-seq实验以及分析总结(上篇)</title>
      <link href="/2019/04/01/chip-seq1/"/>
      <url>/2019/04/01/chip-seq1/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>原创：丸子 宇宙实验媛</strong><br>    <div id="aplayer-kLBQvsXK" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="28287132" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><br><strong>由于基因表达调控机制的复杂性，从不同的层面探究生物问题越来越重要，因此需要我们对多种组学数据的整合分析。从RNA-Seq层面，我们可以探究哪些基因具有显著差异，上调或下调；但是想进一步探究调控某一生物学过程的关键因子（包括顺式调控元件和转录因子），以及哪个转录因子调控了感兴趣的基因，需要结合ChIP-Seq来分析。从ChIP-Seq层面，我们可以研究某个特定转录因子的调控作用，以及调控区的组蛋白修饰等。今天，我们就来学习下ChIP-Seq的实验部分，之后的推送也会为您献上ChIP-Seq的数据分析。</strong><br><a id="more"></a></p><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>染色质免疫共沉淀技术(Chromatin Immunoprecipitation,ChIP)是一种用于研究蛋白质DNA的体内相互作用的经典实验技术。<strong>采用特异性抗体将目的蛋白进行免疫沉淀，由此可以把目的蛋白所结合的基因组DNA片段也富集下来。通过与高通量测序技术的结合，对ChIP后的DNA产物进行测序分析，从全基因组范围内寻找目的蛋白的DNA结合位点，以高效率的测序手段得到高通量的数据结果。</strong><br><img src="/img/chip_seq1.webp" alt="10ba5218a81e48864161922c98e79f75.jpeg"><br>ENCODE数据总览</p><h1 id="技术原理"><a href="#技术原理" class="headerlink" title="技术原理"></a>技术原理</h1><p>在生理状态下，把细胞内的DNA与蛋白质交联（Crosslink）后裂解细胞，分离染色体，通过超声或酶处理将染色质随机切割； 利用抗原抗体的特异性识别反应，将与目的蛋白相结合的DNA片段沉淀下来； 再通过反交联（Reverse crosslink）释放结合蛋白的DNA片段； 纯化； 测序获得DNA片段的序列，最后将这些DNA片段比对到对应的参考基因组上。<br><img src="/img/chip_seq2.webp" alt="10ba5218a81e48864161922c98e79f75.jpeg"><br>ChIP实验原理</p><h1 id="应用领域以及技术优势"><a href="#应用领域以及技术优势" class="headerlink" title="应用领域以及技术优势"></a>应用领域以及技术优势</h1><p>由于 ChIP-Seq 的数据是 DNA 测序的结果，为研究者提供了进一步深度挖掘生物信息的资源，研究者可以在以下几方面展开研究：<br><strong>（1）判断 DNA 链的某一特定位置会出现何种组蛋白修饰； <br>（2）检测 RNA polymerase II 及其它反式因子在基因组上结合位点的精确定位；<br>（3）研究组蛋白共价修饰与基因表达的关系； <br>（4）转录因子研究。ChIP-Seq能够在全基因范围内捕获转录因子或者表观修饰标记结合的目标DNA，鉴定转录因子结合位点，揭示基因调控网络，并且适合多种多样的样本。</strong><br><img src="/img/chip_seq3.webp" alt="10ba5218a81e48864161922c98e79f75.jpeg"><br>表观遗传修饰与转录调控</p><h1 id="实验流程"><a href="#实验流程" class="headerlink" title="实验流程"></a>实验流程</h1><p>（1）甲醛处理细胞，使DNA-protein的相互结合作用被交联固定<br>（2）裂解细胞，得到全细胞的裂解液<br>（3）超声处理或者用限制性内切酶处理，将基因组DNA打断至100-500bp<br>（4）抗体免疫沉淀，在细胞裂解液中加入一抗和beads，进行孵育<br>（5）采用合适的实验条件进行洗脱，并进行解交联<br>（6）通过qPCR对ChIP结果进行验证<br>（7）准备好的ChIP后的DNA样品用于ChIP-Seq建库<br><img src="/img/chip_seq4.webp" alt="10ba5218a81e48864161922c98e79f75.jpeg"><br>ChIP实验流程</p><h1 id="建库流程"><a href="#建库流程" class="headerlink" title="建库流程"></a>建库流程</h1><p>（1）DNA片段末端修复<br>（2）3’端加A碱基<br>（3）连接测序接头<br>（4）PCR扩增及DNA产物片段大小选择（一般为100-300bp，包括接头序列在内）<br>想要了解详细步骤，请参考诺唯赞公司VAHTS™ Universal DNA Library Prep Kit for Illumina® V3。<br><img src="/img/chip_seq5.webp" alt="10ba5218a81e48864161922c98e79f75.jpeg"><br>VAHTS™ Universal DNA Library Prep Kit for Illumina® V3建库原理以及流程VAHTS™ Universal DNA Library Prep Kit for Illumina® V3建库&nbsp;Input DNA量最低可至100 pg，且DNA片段末端修复&amp;加A尾，一步完成。经过了严格的质量控制和功能验证，最大程度上保证了文库构建的稳定性和重复性。</p><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><ul><li>10^6~10^7 个细胞才能保证最终得到10到100ng ChIP DNA。<br>一般10^6可以满足高丰度蛋白（如RNA polymerase II）和局部组蛋白修饰（如H3K4me3）的ChIP。如果是低丰度的转录因子蛋白和其他组蛋白修饰则需要10^7个细胞。</li><li>超声处理在含有SDS的缓冲液中可能会破坏蛋白质－蛋白质和蛋白质－DNA相互作用。<br>但是含有SDS的缓冲液能增加超声的效率，适应与DNA紧密结合的转录因子的ChIP-Seq，如果结合较弱的话不推荐使用加SDS的缓冲液。</li><li>ChIP 样品中如含有明显的蛋白质或离子浓度过高或其它杂质污染，可能会使库检时 2100峰图异常，对建库过程中的酶反应产生影响，导致建库失败。建议在完成ChIP实验后，选择某一已知的阳性DNA结合区域设计Q-PCR实验，由此验证ChIP实验的可靠性。但此建议不适合于没有阳性对照序列的ChIP实验。</li><li>IgG通常pull down非常少的DNA，这样导致在后期的建库过程中PCR Cycles 数增加，导致不能达到作为control去除背景噪音的目的（会缺失和放大部分信息）。因此比较而言，Input更适合作为control。建议用不同公司的抗体来做生物重复，以避免抗体导致的结果差异，保证结果的准确性。<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1>1.Jothi et al. (2008) Genome-wide identification of in vivo protein–DNA binding sites from ChIP-seq data. Nucleic Acids Res 36(16) 5221–5231.<br>2.Bernstein, BE; et al. (2005). “Genomic maps and comparative analysis of histone modifications in human and mouse”. Cell. 120: 169–181.<br>3.Johnson, DS; Mortazavi, A; et al. (2007). “Genome-wide mapping of in vivo protein–DNA interactions”. Science. 316: 1497–1502. </li></ul>]]></content>
      
      
      <categories>
          
          <category> Bio Cooking </category>
          
      </categories>
      
      
        <tags>
            
            <tag> chip-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅谈期刊筛选与文章投稿-上篇</title>
      <link href="/2019/03/31/paper-writing01/"/>
      <url>/2019/03/31/paper-writing01/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>原创： 伊颜落芸 宇宙实验媛 1月3日</strong><br>    <div id="aplayer-rZicBCXY" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="28287132" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><br><strong>随着近十年生物医学科技的迅猛发展，SCI文章的在线发表量以及PubMed等主流数据库对文章的收录数呈指数型增长；尤其是伴随着几大出版集团&gt;的合并重组，开源期刊（OA）的流行，科学研究者越来越重视成果发表的时效性、深刻度和影响力。笔者也参与过多篇SCI论文发表，现就期刊筛选&gt;和论文发表的流程分享一些心得体会，由于篇幅限制，将分为两期讨论，请读者持续关注。</strong><br><a id="more"></a></p><h2 id="编者按"><a href="#编者按" class="headerlink" title="编者按"></a>编者按</h2><p><strong>随着近十年生物医学科技的迅猛发展，SCI文章的在线发表量以及PubMed等主流数据库对文章的收录数呈指数型增长；尤其是伴随着几大出版集团的合并重组，开源期刊（OA）的流行，科学研究者越来越重视成果发表的时效性、深刻度和影响力。笔者也参与过多篇SCI论文发表，现就期刊筛选和论文发表的流程分享一些心得体会，由于篇幅限制，将分为两期讨论，请读者持续关注。</strong></p><h3 id="期刊筛选"><a href="#期刊筛选" class="headerlink" title="期刊筛选"></a>期刊筛选</h3><p>在进行目标杂志的筛选和确定时，采取以下几个核心的原则：<br><strong>1.综合考虑期刊影响力和近５年平均影响因子：发CNS是生物医学研究者的最高目标，它们也是影响力最高的综合性期刊，无论从数据的质量、完整度，科学问题的选择和语言撰写方面都是一流的。</strong><br>取法乎上，得乎其中，取法乎中，得乎其下。我们追求的不是发表CNS的结果，而应该在数据呈现形式，实验设计的角度以及英文文章的撰写这三个方面尽可能高标准看齐。建议遵循小领域期刊&gt;泛领域期刊&gt;综合性期刊。例如一篇研究临床心血管致病机制和临床相关性的文章，选择层级是： JACC&gt; JCI/JEM&gt;Nature Communications/Science Advances。在这些层级范围内，方向的聚焦性逐层递减，而科学问题的接受度和广阔性逐层增加，显而易见反映到次要指标IF上也有所体现。<br><img src="/img/paper_writing1-1.webp" alt="1"><br>另一个重要的指标是五年平均影响因子    受市场因素和编辑部综合决策影响，IF值在2-3年内存在波动较为常见，而五年的时间范围内，能够尽可能排除非学术因素的影响，像Elsevier旗下的Cell系列子刊和Nature旗下子刊，在相当长的周期内，IF的波动都不会太明显，而同出版集团的有些OA杂志可能有比较明显的波动，特别是显著下跌的期刊，存在着大量灌水的可能，比如Cellular Signalling, Stem Cell Reports这几年影响因子下跌，发文量也明显增多，还有已经被列入黑名单和准黑名单的scientific reports，tumor biology以及oncotarget等杂志。<br><strong>2.综合考虑期刊发文量和审稿周期</strong><br>从出版周期上看，一般期刊分为周刊，双周刊，月刊，季刊。有的杂志只有电子版没有纸质版，比如Nature Communications, Scientific Reports等大部分open access期刊，这类期刊的发文量比较多，这给了我们研究该期刊文章风格的参考性，同时也增大了被录用的概率。由于文章投稿人和in press的期刊之间供需关系不平衡，可能存在审稿周期慢的情况，通常在文章的核心论点突出，基本证据链完备的情况下就应该尽早考虑期刊的筛选和布局。因为一旦进入审稿周期，就是编辑方为主的考量，我们虽然可以发站内信催促，但是主动权还是不在我们。<br><strong>3.兼顾考虑期刊编辑友好度及与本研究相关度</strong><br>须知：建立在相当程度的文献阅读基础上，我们才能知道国内外同行的关注度和竞争性。比如研究XX蛋白质的翻译后修饰在某种肿瘤代谢疾病模型中的应用。 第一步，文献查对我们需要知道国内外研究该基因的实验室和课题组有哪些？他们对该基因蛋白质翻译后修饰的研究在哪个层面，特别是首次报道的某种修饰及其调控模式的团队或相关成员，例如近年来关注较多的细胞能量代谢与乙酰化修饰，现在研究系统性较高、占比量较大的工作基本来自于Choudhary、Matthias 团队和华人教授管坤良、熊跃团队，既有蛋白质组学层面的全谱研究【1,2】，又有单基因层面的机制功能研究【3-5】。知悉这些，我们才能大致知道需要关注哪些学者，其基本观点和研究出发点等, 以其投稿结果和期刊类型为参照制定我们的投稿目标；第二步，前审稿阶段 类似各种基金的小同行评审，最好能给了解你工作的相关教授审阅并提出文章架构和数据完整度方面的意见，这是十分必要的，毕竟在实验研究中我们要保持思维方式的独立性，而在投稿过程中需要依赖于导师的学术判断和投稿经验。这一方面取决于之前成功发表的期刊编辑团队是否青睐于本团队所在方向的工作，另一方面取决于拟投稿文章和该期刊近期相关研究方向的工作是否具有研究点的深入和研究面的开发，并在投稿内容中突出和强化这一点；第三步，热点分析 利用Web of Science 或者 基于perl的网络爬虫方法，可以对相关领域内的发文量，以及资助情况进行分析总结。以热点的研究方向Crispr-Cas9介导的基因编辑为例。可见资助情况和发文情况在相关领域的关注度逐年提升。提示我们在投稿杂志选择方面，近3-5年侧重交叉热点整合的文章可能会另编辑更感兴趣。<br><img src="/img/paper_writing1-2.webp" alt="2"><br><img src="/img/paper_writing1-3.webp" alt="3"><br><strong>4.兼顾考虑版面费与是否为开源期刊</strong><br>考虑到科研经费的有限性和时效性，在保证发表期刊质量的前提下，版面费也必须具有高性价比。通常来讲，高版面费的杂志很多是开源期刊，相关文章水平参差不齐的几率更大，所以我们必须综合考虑这些因素并珍惜每个目标期刊的初次投稿机会。</p><h4 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h4><ol><li>Choudhary, C. et al. Lysine acetylation targets protein complexes and co-regulates major cellular functions. Science 325, 834-840 (2009).</li><li>Zhao, S. et al. Regulation of cellular metabolism by protein lysine acetylation. Science327, 1000-1004 (2010).</li><li>Zhao, D. et al. Lysine-5 acetylation negatively regulates lactate dehydrogenase A and is decreased in pancreatic cancer. Cancer cell 23, 464-476 (2013).</li><li>Yang, H.B. et al. Acetylation of MAT IIalpha represses tumour cell growth and is decreased in human hepatocellular cancer. Nature communications 6, 6973 (2015).<br>5.Saito, M. et al. Acetylation of intrinsically disordered regions regulates phase separation. Nature chemical biology 15, 51-61 (2019).<br>这期的总结就到这里，欢迎各位关注者们的分享和讨论。这期重在理论经验，下次将着重就投稿细节展开讨论。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper Writing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper writing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>师兄又在胡扯了-Western Blot</title>
      <link href="/2019/03/31/western-blot/"/>
      <url>/2019/03/31/western-blot/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>大家好，阿呆师兄又出现了。不知道上个月说的几本书有几个人看了或准备看的。其实原本我应该深藏功与名，大隐隐于市了，不知道大家还记不记得短腿师妹前阵子说“宇宙实验媛喊你来拿三位数稿费了”</strong><br><a id="more"></a><br><strong>阿呆  宇宙实验媛</strong><br>大家好，阿呆师兄又出现了。不知道上个月说的几本书有几个人看了或准备看的。其实原本我应该深藏功与名，大隐隐于市了，不知道大家还记不记得短腿师妹前阵子说“宇宙实验媛喊你来拿三位数稿费了”<img src="/img/western_blot_1.webp" alt="c3c84a8589e6d25d17907a22ba50b028.jpeg"><br>一开始在考虑要不要投稿的时候，其实我是拒绝的。因为，你不能让我投，我就马上去投，第一我要酝酿一下，因为我不愿意投完了以后再加一些特技上去，稿子“咣”一下，很亮、很炫，这样观众出来一定会骂我，根本没有内容的稿子，就证明是个假的。后来发生了一件惨绝人寰的事情……<img src="/img/western_blot_2.webp" alt="beb31765f4877abf3a22de358638a62e.jpeg"><br>是的，我的肾6摔了个脸着地。当时第一反应就是，啊！又是一笔开销啊！！手里没粮，心里很慌！于是我就来水了……除了短腿师妹变成了短腿老板外，其他也没什么嘛……（凑表脸）<br>可是写啥呢，大家知道短腿他们偏干实验，而我是个纯种湿实验员，没有干货只会浑水摸鱼……直到有一次和师妹聊天提到Western Blot（WB）。<br><img src="/img/western_blot_3.webp" alt="e4a0335602aa4d04933ba66ab39ebb11.jpeg"><br>好吧我就来试试看写这个，虽然我觉得可能没有观众愿意看这些……毕竟作为一个生物狗，不可能不知道WB啊！我打开了某度，输入“Western Blot”<br><img src="/img/western_blot_4.webp" alt="2405a4979799674c2568dd6c48171307.jpeg"><br>去掉最上面的广告，大家可以看到，确实是随便找找一大把，这还需要我写？就随便点开那个“这一篇就足够了!Western blot详细步骤与经验交流”看下。Emmm……写得蛮清楚的嘛……（唉咦，谁扔的番茄？）好吧好吧，如果你跟着我点进去看了，会发现这个网页里的内容确实基础地描述了WB的过程。但我知道各位看官一定是不会满足于这些。来来反正你都打开网页了，不如点到某度文库里去，请输入“Western_Blot详解及问题分析”看见那个53页的PPT没？没有下载券就和我一样在线看吧，把它仔细看完，WB的理论知识可以说已经掌握了。如果你是个WB小白，现在已经升级成WB王语嫣；如果已经有点经验了，那现在有没有一种通透了的感觉。<br>然而上手做起来依然会有各种问题。很正常啊，不然怎么会有那么多WB技术求教贴、经验分享贴一直在冒出来？做实验不会不知道丁香园论坛的吧，emmm…对对就是那个临床的丁香园。去丁香园论坛搜索“Western Blot”<br><img src="/img/western_blot_5.webp" alt="13f7055b762a88ea746f1bcd8c601ba8.jpeg"><br>我只是随便截图的，各种技术问题几乎都能在上面找到，毕竟你不是第一个吃螃蟹的人。当新手光环还在的时候，一般都会觉得WB果然是个基础实验。当光环褪去的时候，就知道自己连个基础都没有。当然了，有些人可能光环的时间比较长，有些人可能……没有光环……<br>不记得谁说的选择比努力重要，在WB里真是体现的淋漓尽致。上样前你得选合适浓度与孔数的胶，（取决于目标蛋白大小和上样体积）；run起来的时间不能太长也不能太短（还是大小）；转起来除了选时间，先要选择转膜方式和膜的种类（蛋白大小、结果显影还是扫描）；封闭你是选奶粉还是BSA（搞不搞磷酸化）；孵个一抗简直就是WB的灵魂啊没选好全都白辛苦（这个靠try啊）；准备化学发光呢还是荧光……哪一条没选好，努力产生的结果大概率是垃圾（戾气了，要“inner peace”……呼）。<br>如果对WB有点情怀，可以看看丁香园的那篇帖子“【建议】穷人的劳斯莱斯-我的五年western blot体会”老人大概会有点感触吧。好了，就不多说了，字数凑够了，拿去换点米……授人以鱼不如授人以渔嘛，是吧…（还想要鱼？没看见前面写的么，跟我这个浑水摸鱼的人要鱼？）好吧，来个太长不看版吧：去看文库的ppt，不会的朋友当科普，会点的朋友当详细复习，万一醍醐灌顶了呢。动手问题去丁香园，生物秀啥的也行，平时多看看抗体说明书也会有惊喜。反正我就是这么过来的……想苦练WB技艺的朋友可能会对此篇不满吧，哎朋友啊你是不知道，其实我是在帮你啊……<br>贴一个<a href="https://v.youku.com/v_show/id_XNzM4Njk1MTU2.html" target="_blank" rel="noopener">全自动WB仪器的视频</a>若干年后：“在岗位上竞争不过机器是种怎样啊体验”……瑟瑟发抖.jpg<br>（所有图片均来源于网页截图或自己手机截图）</p>]]></content>
      
      
      <categories>
          
          <category> Bio Cooking </category>
          
      </categories>
      
      
        <tags>
            
            <tag> western blot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习数据分析极简思路及sklearn算法小试</title>
      <link href="/2019/03/27/Machine-learnig-KFC/"/>
      <url>/2019/03/27/Machine-learnig-KFC/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>原创：老板，来一打TPU</strong></p>    <div id="aplayer-xddWJTZt" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="28287132" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div><p><strong>机器学习拥有庞大的知识体系，这里对机器学习的数据分析的整个思路和流程作最最简单的归纳。机器学习的步骤大致包括：<br>1）理解和清理数据<br>2）特征选择<br>3）算法建模<br>4）测试评估模型</strong><br><a id="more"></a></p><h1 id="机器学习数据分析极简思路"><a href="#机器学习数据分析极简思路" class="headerlink" title="机器学习数据分析极简思路"></a>机器学习数据分析极简思路</h1><h2 id="1）理解和清理数据"><a href="#1）理解和清理数据" class="headerlink" title="1）理解和清理数据"></a>1）理解和清理数据</h2><ul><li>理解数据<br>数据是机器学习大餐的原始食材，对数据分析起着至关重要的作用，理解原始数据的含义将有助于进一步分析。例如，甲基化图谱与年龄有着显著的相关性，而与性别关系不大，因此在数据分析中，对这两个特征（faeature）需要区别对待。更好的理解方式是直接可视化某些数据，例如对于经典的鸢尾花数据集，可以通过python seaborn绘图包可视化各个特征（feature）之间的关系；对于大数据，则可以进行降维分析（PCOA、tSNE），理解数据组成主成分贡献度。<pre class=" language-python"><code class="language-python">  <span class="token comment" spellcheck="true">#pip install seaborn</span>  <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pyplot  <span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sb  <span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd  <span class="token operator">%</span>matplotlib inline  data<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'iris.csv'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#pandas 读入数据</span>  data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#查看数据</span>  data<span class="token punctuation">.</span>describe<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#数据基本统计</span>  sb<span class="token punctuation">.</span>pairplot<span class="token punctuation">(</span>data<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>hue<span class="token operator">=</span><span class="token string">'Species'</span><span class="token punctuation">)</span> </code></pre>鸢尾花数据组成<br><img src="/img/1.png" alt="32bc1a777af3001e5fc1dea42b93c0d1.png"><br>鸢尾花数据所有feature基本数理统计<br><img src="/img/2.png" alt="2b240766f89ac4edf021b4341265784a.png"><br>鸢尾花数据不同feature相互关系<br><img src="/img/3.png" alt="c6662ebd0cefd5735191807c454d879a.png"></li><li>剔除异常值<br>清理数据的目的在于去除原始数据中的异常值和想办法处理缺失值，我们拿到手上的数据不可能尽善尽美，总有一些妖孽作祟，对于异常值我们应当剔除。举个栗子，假设在鸢尾花数据集中，有一个样本显示鸢尾花花瓣长度10m，其他诸如花瓣宽度、花萼长宽值都正常，可以脑补一下这是一朵什么样的花，那么这个样本显然应该剔除。</li><li>处理缺失值<br>缺失值在数据分析中很常见，总有一些样本观测值会因为这那的问题缺失，处理缺失值如果样本数量很大，而包含缺失值的样本又少，这个时候果断去掉这些样本，眼不见为净；如果因为样本有限或者缺失值太多，就要想办法补全缺失值（imputation）,常常利用逻辑回归建立模型，找出这些数据变化的规律，从而预测缺失值。如何合理推断和填回这些缺失值是一门大学问，哪种方法好，我也不敢妄言。</li></ul><h2 id="2）特征选择"><a href="#2）特征选择" class="headerlink" title="2）特征选择"></a>2）特征选择</h2><p>工业界广泛流传的一句话是：<strong>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已</strong>。由此可见，特征选择是机器学习的关键的关键。特征选择目的在于提取跟目标最为有效的信息，降低数据维度和计算成本，同时防止过拟合（overfitting，训练集特征用的太多太细，以致于在测试集中不适）。要知道，并不是特征越多，结果越好，没有严格意义上的特征累加效应，有时候好的几个特征胜于大量零碎的特征取得的效果。<br>在许多大数据挖掘竞赛中（国内的阿里天池和国外的kaggle平台），最复杂的过程莫过于特征工程建立阶段，大概占据了整个竞赛过程的70%的时间和精力，最终建立的模型的好坏大多也取决于特征工程建立的好坏。遗憾的是，特征工程不像模型建立的过程有着固定的套路，特征工程的建立凭借的更多的是经验，因此没有统一的方法。这里抛砖引玉介绍一些常见的办法，更为详细的内容请参考文后链接。<br><strong>a)特征过滤法</strong><br>比较简单，它按照特征的发散性或者相关性指标对各个特征进行评分，设定评分阈值或者待选择阈值的个数，选择合适特征。例如，我们可以简单的计算出每个feature的方差，方差越大说明这个feature在样本中变异大，即有区分性；而越小的（极端时方差为0），即表示在所有样本中一样，特征选择时则可不考虑这些特征。我们可以选择方差最大的前n个feature用于建模，这就是最为简单的方差筛选法。<br><strong>b)包装法</strong><br>根据目标函数，通常是预测效果评分，每次选择部分特征，或者排除部分特征。<br><strong>c)嵌入法</strong><br>则稍微复杂一点，它先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据权值系数从大到小来选择特征。类似于过滤法，但是它是通过机器学习训练来确定特征的优劣，而不是直接从特征的一些统计学指标来确定特征的优劣。<br><strong>踩雷说：特征选择之后，需要从原始数据矩阵提取相应的特征重构矩阵，那么训练集和测试集的特征经过你各种变换之后，应当保持一一对应，类别和顺序在矩阵中都应该一致。</strong><br>目前，已经有一些套路化的特征选择工具，例如python的FeatureSlector包，见链接。</p><h2 id="3）算法建模"><a href="#3）算法建模" class="headerlink" title="3）算法建模"></a>3）算法建模</h2><p>针对具体的问题，是分类问题？回归问题？还是其他？选择合适的模型，或者使用集成的算法模型。常见的算法模型包括：<br>对于回归问题：<br>a)线性回归（回归，LinearRegression）<br>b)岭回归（回归，Ridge）Ridge是线性回归加L2正则平方，以防止过拟合<br>c)拉索回归（Lasso），加入惩罚函数L1正则绝对值，防止过拟合<br>d)弹性网络回归（回归），同时使用L1和L2正则。<br>e)K近邻（回归和分类，KNeighborsRegressor）<br>f)决策树（回归和分类，DecisionTreeRegressor）<br>g)支持向量机（回归和分类，SVR）</p><p>对于分类问题：<br>a)支持向量机（回归和分类，SVC）<br>b决策树（回归与分类,DecisionTreeClassifier）<br>c)逻辑回归（分类,LogisticRegression)<br>d)LDA线性判别分析（分类,LinearDiscriminantAnalysis)<br>e)K近邻（分类,KNeighborsClassifier)<br>值得一提的是无论是分类还是回归问题，基于决策树和SVM的算法都有比较好的表现。</p><h2 id="4）测试评估模型"><a href="#4）测试评估模型" class="headerlink" title="4）测试评估模型"></a>4）测试评估模型</h2><p>测试评估模型的目的在于，解决模型的欠拟合（under-fitting）和过拟合（over-fitting）问题，通过即时的反馈不断调整模型、优化模型，使得模型更加稳健。<br>实际上，测试评估模型应该在你建模之前就考虑，例如是否需要设置纯粹的外部数据验证集，若没有这样的数据，你怎样划分数据进行建模预测？<br>在实际训练中，模型通常对训练数据好，但是对训练数据之外的数据拟合程度差。用于评价模型的泛化能力（即模型普适性）。交叉验证的基本思想是把在某种意义下将原始数据进行分组,一部分做为训练集(train set),另一部分做为验证集(validation set or test set),首先用训练集对模型进行训练,再利用验证集来测试模型的泛化误差。另外，现实中数据总是有限的，为了对数据形成重用，比较常用的是k-fold交叉验证法。测试评估模型的时候，常常结合AUC曲线判断模型好坏。</p><h1 id="sklearn-算法小试"><a href="#sklearn-算法小试" class="headerlink" title="sklearn 算法小试"></a>sklearn 算法小试</h1><h2 id="实现目的"><a href="#实现目的" class="headerlink" title="实现目的"></a>实现目的</h2><p>sklearn是python中一个强大的机器学习模块,拥有众多的机器学习算法和功能。这里，通过sklearn的datasets构建一个数据集，并用4种常用算法：逻辑回归（LogisticRegression）、支持向量机（SVM）、决策树（DecisionTree）和集成算法（VotingClassifier）对训练集建模，然后对测试集预测，最终通过得分看一下4种算法的差异。</p><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>1）构建本次使用的数据集<br>2）将数据拆分成训练集和测试集<br>3）用4种算法分别建模、预测</p><h2 id="代码环境"><a href="#代码环境" class="headerlink" title="代码环境"></a>代码环境</h2><p>python版本：python3<br>1）如果不想被python各种安装包困扰，推荐Jupyter在线python，<a href="https://jupyter.org/" target="_blank" rel="noopener">Jupyter官网</a>，点击”Try Jupyter with Python”，点击“+”号即可。安装包的时候直接pip install packages_name,例如pip install sklearn,点击“Run”，提示“Successfully installed sklearn-0.0”即安装完成。<br><img src="/img/4.png" alt="a3e70c182d26dd77208c02cab6571af5.png"><br>2）Pycharm，专业、高效、强大的python开发端。</p><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><pre class=" language-python"><code class="language-python">    <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np    <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt    <span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets <span class="token comment" spellcheck="true">#built-in datasets</span>    <span class="token comment" spellcheck="true">#make_moons,generated datasets</span>    X<span class="token punctuation">,</span>y <span class="token operator">=</span> datasets<span class="token punctuation">.</span>make_moons<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>noise<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span>y<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X<span class="token punctuation">[</span>y<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span>y<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X<span class="token punctuation">[</span>y<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#plot for datasets</span>    <span class="token comment" spellcheck="true">#split datasets for train and test part</span>    <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split    X_train<span class="token punctuation">,</span>X_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#1.logistic regression model</span>    <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression    log_clf<span class="token operator">=</span>LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#create LR classifer</span>    log_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#train and fit the model</span>    log_score<span class="token operator">=</span>log_clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#test the model</span>    <span class="token comment" spellcheck="true">#2.svm model</span>    <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC    svm_clf<span class="token operator">=</span>SVC<span class="token punctuation">(</span><span class="token punctuation">)</span>    svm_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>    svm_score<span class="token operator">=</span>svm_clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#3.decision tree model</span>    <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier    dt_clf<span class="token operator">=</span>DecisionTreeClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>    dt_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>    dt_score<span class="token operator">=</span>dt_clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#4.ensemble method</span>    <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> VotingClassifier    voting_clf<span class="token operator">=</span>VotingClassifier<span class="token punctuation">(</span>estimators<span class="token operator">=</span>                                <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'log_clf'</span><span class="token punctuation">,</span>LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 <span class="token punctuation">(</span><span class="token string">'svm_clf'</span><span class="token punctuation">,</span>SVC<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 <span class="token punctuation">(</span><span class="token string">'dt_clf'</span><span class="token punctuation">,</span>DecisionTreeClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                                 <span class="token punctuation">]</span><span class="token punctuation">,</span>voting<span class="token operator">=</span><span class="token string">"hard"</span><span class="token punctuation">)</span>    voting_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>    voting_score<span class="token operator">=</span>voting_clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"log score:%s"</span><span class="token operator">%</span>log_score<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"svm score:%s"</span><span class="token operator">%</span>svm_score<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"dt score:%s"</span><span class="token operator">%</span>dt_score<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"voting score:%s"</span><span class="token operator">%</span>voting_score<span class="token punctuation">)</span></code></pre><p>构建数据集：<br><img src="/img/5.png" alt="c6e3145820fe446499bfe5166f85b29e.png"><br>4种算法预测结果：<br><img src="/img/6.png" alt="a59578cf44dee88a46ef0bcceabf1b2b.png"><br>可以看到，单一算法SVM比较好，集成算法较单一的算法还是有一定的提高。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.zhihu.com/question/28641663?utm_source=wechat_search&amp;utm_medium=organic" target="_blank" rel="noopener">机器学习中，有哪些特征选择的工程方法？</a><br><a href="https://mp.weixin.qq.com/s?__biz=Mzg5ODAzMTkyMg==&amp;mid=2247485387&amp;idx=1&amp;sn=d22618f98adae3c9038184b9c4991ea2&amp;chksm=c0698f96f71e06807bbb3c667d50aa87899aa8d7b48bab51be33206390a03cb2e28d3ddb27b4&amp;mpshare=1&amp;scene=24&amp;srcid=0327GWk8nsWdgLT2kYwpeazY#rd" target="_blank" rel="noopener">FeatureSlector:一个可以进行机器学习特征选择的python工具</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI2MjE3OTA1MA==&amp;mid=2247484860&amp;idx=1&amp;sn=7ea3597474f5ceaf443f10d63a8217ee&amp;chksm=ea4e5439dd39dd2f2f0cd95eca909e2ab255fc5dc6e033e9b2d265bf2124751f32e96279188d&amp;scene=7#rd" target="_blank" rel="noopener">机器学习中的交叉验证</a></p>]]></content>
      
      
      <categories>
          
          <category> Machine Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UBGBs</title>
      <link href="/2019/03/20/UBGBs/"/>
      <url>/2019/03/20/UBGBs/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>Yeap,Family!</strong><br><a id="more"></a><br><img src="/img/WechatIMG201.jpeg" alt="b"><br><img src="/img/WechatIMG262.jpeg" alt="c"></p>]]></content>
      
      
      <categories>
          
          <category> Photo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> photo </tag>
            
            <tag> family </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅谈科研论文发表与投稿-下篇</title>
      <link href="/2019/03/19/paper-submit-experience/"/>
      <url>/2019/03/19/paper-submit-experience/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>原创： 伊颜落芸  宇宙实验媛<br>生物医学科学研究的过程犹如马拉松长跑，投稿的经历更是具有西天取经般的朝圣感。上线发表的文章只是最后的工作总结之一，背后的故事&gt;往往更精彩。 上篇我们已经就期刊筛选分享了初步经验，本期将以发表在Nature Communications中题为Znhit1 controls intestinal stem cell maintenance by regulating H2A.Z incorporation的工作为例，就论文投稿和回修过程论述心得体会，便于读者熟悉投稿的关键环节并规避常见误区。</strong><br><a id="more"></a></p><p>   Nature Communications 杂志作为NPG旗下开源期刊，近几年不光收录文章数量质量上升，交互性功能也日趋开放。值得一提的是，大多数文章上传了同行评审（peer review process）的记录，使读者在欣赏高水平研究工作的同时，也能全面了解到文章的逻辑性提升过程和实验证据完善的过程。<br>     这篇文章讲述的是SRCAP染色质重塑复合体的重要组分—锌指蛋白Znhit1，通过促进组蛋白变异体H2A.Z整合到和Lgr5+肠道上皮细胞命运决定相关基因的TSS区域，增强其分子伴侣YL1的相互作用和磷酸化，进而维持Lgr5+细胞的干性稳态并促进小肠上皮平衡的故事。结合peer review file。我们凝练出以下五个投稿过程要点：</p><h2 id="1-初次投稿注意事项"><a href="#1-初次投稿注意事项" class="headerlink" title="1. 初次投稿注意事项"></a>1. 初次投稿注意事项</h2><p>   首先要根据拟投稿的期刊，认真阅读投稿指南，确认正文材料和补充材料在形式和内容上符合杂志社的要求。如果能在初次投稿时候准备完善，将给编辑和审稿人工作可信度高和完成度高的良好印象。<br>即使是同一个出版社的不同子刊也可能在这些方面存在很大差异。以NPG集团为例：主刊和经典子刊，uncropped scans 和 reportingsummary （图1）应该在数据的整理阶段完成，后者的统计学分析方法，原始生物信息的溯源，和其他重要实验方法的陈述亦可辅助文章的撰稿过程。这些细节也是审稿人评价本工作严谨性和完成度的重要层面，因此不可掉以轻心。该集团其余代表性刊物ncogene、Cell Death andDsease虽然要求不同，但是如能秉承“取法乎上”的原则一定能得到好的效果。<br><img src="/img/paper_writing_1.webp" alt="01"><br>   其次的重点就是Cover Letter了，好的CV应该观点突出，逻辑清楚。通常都是体现“发现了什么”，“几大创新点”这样的逻辑思路，当然也可根据投稿杂志的领域类型和刊物亚类进行相应调整。如果一份cover letter不能吸引到审稿人，就像招聘时简历不能得到HR的青睐，由此摘要的部分可能也不够凝练突出。总结起来这两个部分就是功夫在平时，投稿再加强。</p><h2 id="2-如何评价初次回修审稿意见"><a href="#2-如何评价初次回修审稿意见" class="headerlink" title="2. 如何评价初次回修审稿意见"></a>2. 如何评价初次回修审稿意见</h2><p>   从这篇文章的投稿历程看，初次投稿时间2017.07.07，收稿日期为2019.02.15。虽然不能轻易评价该工作在初次投稿时与杂志社的投稿标准间的差距和差异，但从审稿人提出的问题来看，原始版本还是存在很多细节问题和可提升空间。可以总结为以下几个层面：<br><strong>a.  检测指标：</strong><br>审稿人认为需要关注Znhit1在小肠上皮中的表达模式，才能更好的确认Znhit1对肠稳态的调控是依赖对小肠上皮干细胞的调节实现，而非通过goblet细胞或肠内分泌细胞；<br><strong>b.  评价指标：</strong><br>审稿人认为单独通过Lgr5+ISC的缺失不足以评价小肠上皮的稳态失衡，毕竟还有+4 Bmi1+ 细胞、Dll1+分泌前体细胞、Alpi+肠上皮前体细胞发挥的代偿效应；<br><strong>c.  模型选择：</strong><br>审稿人认为经典的表征Lgr5+的小肠干细胞所选用的工具鼠模型还应包括Lgr5-EGFP-IRES-creERT，作者选择的模型Olfm4-CreER似乎并不是一个最佳的标记指标。<br><strong>d.  开放问题:</strong><br>审稿人认为作者提到的Znhit1调控yl-1磷酸化的机制不足从机制上揭示Znhit1对Lgr5+干细胞的调控，需要提供更多的修饰启动者，修饰位点，修饰模式和结合区域等的详细信息。<br>虽然不同的文章研究内容迥异，但是审稿人提出问题的架构有迹可循。这篇文章在初次投稿时获得了3个审稿人的评审意见，其中a.c.d三点在多个审稿人处提及，结合这篇文章的审稿意见和笔者自身的投稿经历，可总结为：<strong>共性问题着重回答，开放问题难点攻破，合理质疑引用文献，数据highlight，remark中关注态度。</strong></p><h2 id="3-写好回修信"><a href="#3-写好回修信" class="headerlink" title="3. 写好回修信"></a>3. 写好回修信</h2><p>   在对审稿意见进行客观全面的分析+针对性的实验补充后，回修信的撰写是对文章调整进步的总结。核心原则有四：<br>1)  点对点 作者对所有调整的图片内容进行了详细的梳理和总结（图2）；<br><img src="/img/paper_writing_2.webp" alt="02"><br>2)  全面性 不论该问题出现在审稿人的综合评述中还是单独的major/minor concerns，建议均进行必要的回复；<br>3)  不卑不亢 审稿人提出的质疑及其佐证的参考文献，如能丰富文章架构和纠正偏颇，应该加以肯定；如果原有数据与提出质疑一致，也可以rebuttal，但前期是基于对所指文献和观点的充分了解和对观点原创者的深入认知，否则还是不要班门弄斧；<br>4)  忌画蛇添足 这一点在回答开放问题时尤其注意。</p><h2 id="4-多轮回修的心理和技术储备"><a href="#4-多轮回修的心理和技术储备" class="headerlink" title="4. 多轮回修的心理和技术储备"></a>4. 多轮回修的心理和技术储备</h2><p>   文章一旦踏上投稿过程，便是开弓没有回头箭之感，多轮回修更是司空见惯。在这个过程中需要积极的寻求相关领域专家专业意见和导师的讨论指点，寻求合作来弥补技术的短板；需要补实验小分队相互沟通缓解疲乏和压力。或许成为一个杰出的科学研究工作者，最重要的是心态，其次才是技术，一篇篇的文章是提升和总结也是修行，切不可偏执。</p><h2 id="5-正式发表前的材料准备"><a href="#5-正式发表前的材料准备" class="headerlink" title="5. 正式发表前的材料准备"></a>5. 正式发表前的材料准备</h2><p>   编辑部的主体接受或接收函到手并不能马上庆祝最后的胜利，还需按照要求重点准备各项材料。原始图片：尤其在分辨率和图片的格式要求上进行二次审核；统计学方法的选择，代表性图片的呈现是否符合投稿要求；文字的表示和单词拼写是否有错误。特别注意：图片的信息标注要反复检查一遍，这是最容易出现疏漏的环节。</p><p>最后祝大家都能享受充实的投稿过程！！<br><a href="http://www.universebiologygirl.com/2019/03/19/paper-submit-experience/" target="_blank" rel="noopener">科研论文写作与投稿-上篇</a></p>]]></content>
      
      
      <categories>
          
          <category> Paper Writing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper writing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Date with Bioawk</title>
      <link href="/2019/03/16/Date-with-Bioawk/"/>
      <url>/2019/03/16/Date-with-Bioawk/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>原创：老板，来一打TPU</strong></p><h1 id="废话"><a href="#废话" class="headerlink" title="废话"></a>废话</h1><p>这是生平第一篇blog，因此难免要说点废话，所以前戏，啊不对，前言就叫废话吧。git+hexo搭建的平台杠杠的，感谢师弟MingLian小大佬成功带入<br>写blog的坑。第一篇就拿生信李恒大神的神作bioawk镇楼吧！**<br><a id="more"></a></p><h1 id="bioawk简介"><a href="#bioawk简介" class="headerlink" title="bioawk简介"></a>bioawk简介</h1><p>除了鼎鼎大名的BWA、samtools等，李恒大神应群众呼声又做了出于awk又胜于awk的bioawk<br>供广大生信猿们玩耍。bioawk是用C写的，用法和awk基本一样。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="分步安装"><a href="#分步安装" class="headerlink" title="分步安装"></a>分步安装</h3><pre class=" language-bash"><code class="language-bash">    $ <span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> byacc <span class="token function">git</span>    <span class="token comment" spellcheck="true">#安装git</span>    $ <span class="token function">git</span> clone git://github.com/lh3/bioawk.git  <span class="token comment" spellcheck="true">#默认安装在当前目录</span>    <span class="token function">git</span> clone git://github.com/lh3/bioawk.git <span class="token variable">${path}</span>/bioawk <span class="token comment" spellcheck="true">#若加path则必须为空，因此可在想要安装的目录下起一个新名称，git会clone到其下</span>    $ <span class="token function">cd</span> bioawk    $ <span class="token function">make</span>    $ <span class="token keyword">echo</span> <span class="token string">"export PATH=<span class="token variable">${path}</span>/bioawk/:\<span class="token variable">${PATH}</span>"</span> <span class="token operator">>></span> ~/.bashrc    $ <span class="token keyword">.</span>  ~/.bashrc<span class="token comment" spellcheck="true">### 一步安装脚本</span>    <span class="token comment" spellcheck="true">#!/bin/bash</span>    <span class="token function">read</span> -p  <span class="token string">'Input installed  path: '</span> tmp_path    path<span class="token operator">=</span><span class="token variable">${tmp_path/\//}</span>    <span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token operator">!</span> -d <span class="token string">"<span class="token variable">${path}</span>"</span> <span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">then</span> <span class="token keyword">echo</span> <span class="token string">"No such file:<span class="token variable">${path}</span>"</span> <span class="token operator">&amp;&amp;</span> <span class="token keyword">exit</span> <span class="token punctuation">;</span><span class="token keyword">fi</span>    <span class="token function">git</span> clone git://github.com/lh3/bioawk.git <span class="token variable">${path}</span>/bioawk <span class="token operator">&amp;&amp;</span> \    <span class="token function">cd</span> <span class="token variable">${path}</span>/bioawk <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token operator">&amp;&amp;</span> \    <span class="token keyword">echo</span> <span class="token string">"export PATH=<span class="token variable">${path}</span>/bioawk/:\<span class="token variable">${PATH}</span>"</span> <span class="token operator">>></span> ~/.bashrc  <span class="token operator">&amp;&amp;</span> <span class="token keyword">.</span>  ~/.bashrc <span class="token operator">&amp;&amp;</span> \    <span class="token keyword">echo</span> <span class="token string">'Successfully install bioawk!'</span> <span class="token operator">||</span> <span class="token keyword">echo</span> <span class="token string">'Failed install bioawk'</span></code></pre><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>bioawk基本思想是把组成不同类型的文件（sam、bam、fasta、fastq、vcf etc）的基本元<br>素封装成变量，直接调用即可。</p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><pre class=" language-bash"><code class="language-bash">usage: bioawk <span class="token punctuation">[</span>-F fs<span class="token punctuation">]</span> <span class="token punctuation">[</span>-v var<span class="token operator">=</span>value<span class="token punctuation">]</span> <span class="token punctuation">[</span>-c fmt<span class="token punctuation">]</span> <span class="token punctuation">[</span>-tH<span class="token punctuation">]</span> <span class="token punctuation">[</span>-f progfile <span class="token operator">|</span> <span class="token string">'prog'</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>file <span class="token punctuation">..</span>.<span class="token punctuation">]</span>-c 支持输入文件格式，查看帮助：    bioawk -c -hbed:        1:chrom 2:start 3:end 4:name 5:score 6:strand 7:thickstart 8:thickend 9:rgb 10:blockcount 11:blocksizes 12:blockstartssam:        1:qname 2:flag 3:rname 4:pos 5:mapq 6:cigar 7:rnext 8:pnext 9:tlen 10:seq 11:qualvcf:        1:chrom 2:pos 3:id 4:ref 5:alt 6:qual 7:filter 8:infogff:        1:seqname 2:source 3:feature 4:start 5:end 6:score 7:strand 8:frame 9:attributefastx:        1:name 2:seq 3:qual 4:comment</code></pre><p><strong>上面出现的名称即可引用其变量</strong></p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><ul><li><p>打印fasta序列ID、序列、长度、GC含量</p><pre class=" language-bash"><code class="language-bash">bioawk -cfastx <span class="token string">'{print "ID: "<span class="token variable">$name</span>"\tlength: "length(<span class="token variable">$seq</span>)"\tGC: "gc(<span class="token variable">$seq</span>)"\t"<span class="token variable">$seq</span>}'</span> demo.fa</code></pre><p>结果:<br>  ID: g1  length: 18      GC: 0.722222    atcccccccccccccttt<br>  ID: g2  length: 26      GC: 0.0769231   cattatatcttatttttttttttttt<br>  ID: g3  length: 48      GC: 0.229167    acccccccccctttttttttttttcatttttttttttttttttttttt<br>原始文件：</p><blockquote><p>g1<br>  atcccccccccccccttt<br>g2 enzyme<br>  cattatatcttatttttttttttttt<br>g3<br>  accccccccccttttttttttttt<br>  catttttttttttttttttttttt<br>注意：<br><strong>可以看到bioawk在提取ID的时候只提取了空格分隔后的第一个字段，默认输出域分割符是\t</strong></p></blockquote></li><li><p>输出反向互补序列</p><pre class=" language-bash"><code class="language-bash">bioawk -cfastx <span class="token string">'{print <span class="token variable">$name</span>,<span class="token variable">$seq</span>,revcomp(<span class="token variable">$seq</span>)}'</span> demo.fa</code></pre><p>结果：<br>  g1      atcccccccccccccttt      aaagggggggggggggat<br>  g2      cattatatcttatttttttttttttt      aaaaaaaaaaaaaataagatataatg<br>  g3      acccccccccctttttttttttttcatttttttttttttttttttttt        aaaaaaaaaaaaaaaaaaaaaatgaaaaaaaaaaaaaggggggggggt</p></li><li><p>根据序列ID提取序列，这个是最爱的功能</p><pre class=" language-bash"><code class="language-bash">bioawk -cfastx <span class="token string">'BEGIN{while((getline k &lt;"id.txt")>0)i[k]=1}{if(i[<span class="token variable">$name</span>])print ">"<span class="token variable">$name</span>"\n"<span class="token variable">$seq</span>}'</span> demo.fa</code></pre><p>id.txt:<br>  g1<br>  g2<br>  g2 enzyme</p><blockquote><p>g3</p></blockquote></li></ul><p>结果：<br>    &gt;g1<br>    atcccccccccccccttt<br>    &gt;g2<br>    cattatatcttatttttttttttttt<br>注意：id.txt 需要去掉&gt;</p><ul><li>当然还有其他的花样，大家自己去探索吧</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://github.com/lh3/bioawk" target="_blank" rel="noopener">https://github.com/lh3/bioawk</a></p>]]></content>
      
      
      <categories>
          
          <category> Software </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bioinformatics </tag>
            
            <tag> bioawk </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MARKDOWN&#39;s KFC</title>
      <link href="/2019/03/16/MARKDOWN-s-KFC/"/>
      <url>/2019/03/16/MARKDOWN-s-KFC/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>Markdown 是一种轻量级的「标记语言」，创始人为约翰·格鲁伯，用简洁的语法代替排版，目前被越来越多的知识工作者、写作爱好者、程序员或研究员广泛使用。其常用的标记符号不超过十个，相对于更为复杂的 HTML 标记语言来说，Markdown 十分的轻量，学习成本也不需要太多，且一旦熟&gt;悉这种语法规则，会有沉浸式编辑的效果。</strong><br><a id="more"></a></p><h1 id="MARKDOWN使用"><a href="#MARKDOWN使用" class="headerlink" title="MARKDOWN使用"></a>MARKDOWN使用</h1><h2 id="Markdown-是什么？"><a href="#Markdown-是什么？" class="headerlink" title="Markdown 是什么？"></a>Markdown 是什么？</h2><p>Markdown 是一种轻量级的「标记语言」，创始人为约翰·格鲁伯，用简洁的语法代替排版，目前被越来越多的知识工作者、写作爱好者、程序员或研究员广泛使用。其常用的标记符号不超过十个，相对于更为复杂的 HTML 标记语言来说，Markdown 十分的轻量，学习成本也不需要太多，且一旦熟悉这种语法规则，会有沉浸式编辑的效果。<br>另外，印象笔记 Markdown 支持 CommonMark 和 GFM (GitHub Flavored Markdown) 标准。</p><h2 id="印象笔记里-Markdown-有什么特点？"><a href="#印象笔记里-Markdown-有什么特点？" class="headerlink" title="印象笔记里 Markdown 有什么特点？"></a>印象笔记里 Markdown 有什么特点？</h2><ul><li>一键创建：支持 Markdown 独立的一键新建入口，为深度 Markdown 用户提供更好的效率体验；</li><li>支持丰富的主流 Markdown 语法：支持文字相关样式、序号列表、任务列表、表格、TOC 目录、多种图表、数学公式、流程图、时序图、甘特图等；</li><li>支持插入图片：可插入网络图片 或 直接拖动本地图片、复制剪贴板中的图片到 Markdown 笔记中；</li><li>支持多种模式切换：编辑与预览模式、纯编辑模式以及纯预览模式；</li><li>支持多种编辑主题：预置了白色、黑色、深空灰和印象绿主题，默认为印象绿，未来会有更多主题提供；</li><li>跨平台同步：创建的 Markdown 笔记可在登录了印象笔记帐户的各端查看，未来更多端会支持创建和编辑 Markdown 笔记；</li><li>演示模式：Markdown 笔记支持演示模式查看；</li><li>支持其他印象笔记特点功能：笔记标注、导出 PDF、设置提醒、工作群聊共享-查看&amp;编辑笔记等。</li></ul><h2 id="如何创建-Markdown-笔记？"><a href="#如何创建-Markdown-笔记？" class="headerlink" title="如何创建 Markdown 笔记？"></a>如何创建 Markdown 笔记？</h2><ol><li>点击左上角「新建 Markdown 笔记」来创建新的 Markdown 笔记</li><li>点击顶部菜单栏-文件-新建Markdown笔记</li><li>使用快捷键 CMD+D 来快速创建 Markdown 笔记</li></ol><h2 id="印象笔记-Markdown-笔记支持哪些语法？"><a href="#印象笔记-Markdown-笔记支持哪些语法？" class="headerlink" title="印象笔记 Markdown 笔记支持哪些语法？"></a>印象笔记 Markdown 笔记支持哪些语法？</h2><p>—— 以下语法均支持在编辑工具栏直接操作 —— </p><ol><li><p>设置分级标题<br>语法示例：</p><h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><h6 id="六级标题"><a href="#六级标题" class="headerlink" title="六级标题"></a>六级标题</h6></li><li><p>加粗文本<br>语法示例：<br><strong>印象笔记</strong></p></li><li><p>斜体<br>语法示例：<br><em>印象笔记</em></p></li><li><p>下划线<br>语法示例：<br><u>印象笔记</u></p></li><li><p>删除线<br>语法示例：<br><del>印象笔记不支持Markdown</del></p></li><li><p>添加分隔线<br>语法示例：</p></li></ol><hr><ol start="7"><li><p>引用文本<br>语法示例：</p><blockquote><p>近日，印象笔记宣布完成重组。作为Evernote已在中国独立运营近6年的品牌，印象笔记将成为由中方控股的中美合资独立运营实体，并获得红杉宽带跨境数字产业基金首轮数亿元人民币投资。</p></blockquote></li><li><p>添加符号列表或者数字列表<br>语法示例：<br>使用 iOS 版本印象笔记如何快速保存内容？</p></li><li>启用印象笔记 Widget ——印象笔记·剪贴板</li><li>复制粘贴任意内容<ul><li>微信</li></ul></li><li>滑动到 Widget 插件区域即可完成保存<br>印象笔记·剪贴板有什么特点？</li></ol><ul><li>快：开启自动模式，可以自动保存剪贴板的任意内容</li><li>一切：只要可以复制粘贴就可以保存</li><li>有序：全部保存在「我的剪贴板」笔记本并以时间来命名</li></ul><ol start="9"><li>添加待办事项<br>语法示例：<br>三只青蛙</li></ol><ul><li style="list-style: none"><input type="checkbox" checked> 第一只青蛙</li><li style="list-style: none"><input type="checkbox"> 第二只青蛙</li><li style="list-style: none"><input type="checkbox"> 第三只青蛙</li></ul><ol start="10"><li><p>插入链接<br>语法示例：<br><a href="https://www.yinxiang.com/" target="_blank" rel="noopener">印象笔记官网</a></p></li><li><p>插入图片<br>印象笔记支持嵌入网络图片或者直接拖入本地图片，其中本地图片格式支持 jpg、png 和 gif。<br>语法示例：<br><img src="https://www.yinxiang.com/blog/wp-content/uploads/2018/07/%E5%94%AE%E7%A5%A8%E5%BE%AE%E4%BF%A1%E5%B0%81%E9%9D%A22.png" alt="image"></p></li></ol><p>另外，针对插入的本地图片可以控制图片大小，在拖拽、拷贝或者点击插入本地图片之后，直接在图片名称后面（无需空格）添加以下语法均可以按照以下要求控制图片大小：</p><ul><li>@w=300</li><li>@h=150</li><li>@w=200h=100</li><li>@h=100w=200<br>示例笔记<br>782d277a1dbc7dea8480267cf5f87ebd.png@w=300</li></ul><ol start="12"><li><p>插入表格<br>语法示例：<br>| 帐户类型 | 免费帐户 | 标准帐户 | 高级帐户 |<br>| — | — | — | — |<br>| 帐户流量 | 60M | 1GB | 10GB |<br>| 设备数目 | 2台 | 无限制 | 无限制 |<br>| 当前价格 | 免费 | ￥8.17/月 | ￥12.33/月|</p></li><li><p>插入图表<br>目前支持饼状图、折线图、柱状图和条形图，只需将 type 改为对应的pie、line、column 和 bar。</p><pre class=" language-chart"><code class="language-chart">,预算,收入,花费,债务June,5000,8000,4000,6000July,3000,1000,4000,3000Aug,5000,7000,6000,3000Sep,7000,2000,3000,1000Oct,6000,5000,4000,2000Nov,4000,3000,5000,type: pietitle: 每月收益x.title: Amounty.title: Monthy.suffix: $</code></pre></li><li><p>插入行内代码或代码块<br>印象笔记 Markdown 语法支持几十种编程语言的高亮的显示。<br>语法示例：</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#!/usr/bin/python</span><span class="token keyword">import</span> reline <span class="token operator">=</span> <span class="token string">"Cats are smarter than dogs"</span>matchObj <span class="token operator">=</span> re<span class="token punctuation">.</span>match<span class="token punctuation">(</span> r<span class="token string">'(.*) are (.*?) .*'</span><span class="token punctuation">,</span> line<span class="token punctuation">,</span> re<span class="token punctuation">.</span>M<span class="token operator">|</span>re<span class="token punctuation">.</span>I<span class="token punctuation">)</span><span class="token keyword">if</span> matchObj<span class="token punctuation">:</span><span class="token keyword">print</span> <span class="token string">"matchObj.group() : "</span><span class="token punctuation">,</span> matchObj<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token string">"matchObj.group(1) : "</span><span class="token punctuation">,</span> matchObj<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token string">"matchObj.group(2) : "</span><span class="token punctuation">,</span> matchObj<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span><span class="token keyword">print</span> <span class="token string">"No match!!"</span></code></pre></li></ol><ol start="15"><li><p>插入数学公式<br>印象笔记 Markdown 支持绝大多数的 LaTeX 数学公式<br>语法示例：</p><pre class=" language-math"><code class="language-math">e^{i\pi} + 1 = 0</code></pre><p>更多数学公式的输入可以参考： <a href="https://khan.github.io/KaTeX/docs/supported.html" target="_blank" rel="noopener">https://khan.github.io/KaTeX/docs/supported.html</a></p></li><li><p>插入流程图<br>语法示例：</p><pre class=" language-mermaid"><code class="language-mermaid">graph TDA[模块A] -->|A1| B(模块B)B --> C{判断条件C}C -->|条件C1| D[模块D]C -->|条件C2| E[模块E]C -->|条件C3| F[模块F]</code></pre></li></ol><ol start="17"><li>插入时序图<br>语法示例：<pre class=" language-mermaid"><code class="language-mermaid">sequenceDiagramA->>B: 是否已收到消息？B-->>A: 已收到消息</code></pre></li></ol><ol start="18"><li><p>插入甘特图<br>语法示例：</p><pre class=" language-mermaid"><code class="language-mermaid">gantttitle 甘特图dateFormat YYYY-MM-DDsection 项目A任务1 :a1, 2018-06-06, 30d任务2 :after a1 , 20dsection 项目B任务3 :2018-06-12 , 12d任务4 : 24d</code></pre></li><li><p>设置目录<br>设置之后可以自动根据设置的分级标题来自动生成目录。<br>语法示例：<br>[TOC]</p></li></ol><h1 id="FBI-waring"><a href="#FBI-waring" class="headerlink" title="FBI waring"></a>FBI waring</h1><p>本篇文档完全搬运自markdown官方中文文档，仅供测试网页使用，如侵删。<br><a href="https://list.yinxiang.com/markdown/eef42447-db3f-48ee-827b-1bb34c03eb83.php" target="_blank" rel="noopener">https://list.yinxiang.com/markdown/eef42447-db3f-48ee-827b-1bb34c03eb83.php</a></p>]]></content>
      
      
      <categories>
          
          <category> Software </category>
          
      </categories>
      
      
        <tags>
            
            <tag> markdown usage </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
