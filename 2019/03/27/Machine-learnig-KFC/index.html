
<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="UTF-8">
    <title>机器学习数据分析极简思路及sklearn算法小试 | Universe Biology Girls and Boys</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content>
    <meta name="description" content="原创：老板，来一打TPU

    
机器学习拥有庞大的知识体系，这里对机器学习的数据分析的整个思路和流程作最最简单的归纳。机器学习的步骤大致包括：1）理解和清理数据2）特征选择3）算法建模4）测试评估模型
机器学习数据分析极简思路1）理解和清理数据
理解数据数据是机器学习大餐的原始食材，对数据分析起着至关重要的作用，理解原始数据的含义将有助于进一步分析。例如，甲基化图谱与年龄有着显著的相关性，而与性别关系不大，因此在数据分析中，对这两个特征（faeature）需要区别对待。更好的理解方式是直接可视化某些数据，例如对于经典的鸢尾花数据集，可以通过python seaborn绘图包可视化各个特征（feature）之间的关系...">
    
        <link rel="icon" href="/favicon.ico">
    
    
        
            <link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
        
            <link rel="stylesheet" href="/css/stage.css">
        
            <link rel="stylesheet" href="/css/avatar-bg.css">
        
    
<link rel="stylesheet" href="/assets/css/APlayer.min.css" class="aplayer-style-marker">
<script src="/assets/js/APlayer.min.js" class="aplayer-script-marker"></script>
<script src="/assets/js/Meting.min.js" class="meting-script-marker"></script>
</head>
</html>
<body>
<header id="header">
    <div class="menu">
        <i class="fa fa-bars"></i>
    </div>
    <div class="header-main">
        <h1><a href="/">Universe Biology Girls and Boys</a></h1>
    </div>
    <div id="nav">
        <div class="nav-img" id="nav-img"></div>
        <div class="sentences">
            三年八班的周杰伦，来跑个PCR
	</div>
    </div>
</header>

<div id="content-outer">
    <div id="content-inner">
        <div class="clearfix">
    <article id="post">
        <h1>机器学习数据分析极简思路及sklearn算法小试</h1>
        <div class="create">
            <span>Created</span>
            
                <time datetime="2019-03-27T09:30:23.000Z">
                    2019-03-27
                </time>
            
            <ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Machine-Learning/">Machine Learning</a></li></ul>
        </div>
        <p><strong>原创：老板，来一打TPU</strong></p>

    <div id="aplayer-bVLUndeV" class="aplayer aplayer-tag-marker meting-tag-marker" data-id="28287132" data-server="netease" data-type="song" data-mode="circulation" data-autoplay="false" data-mutex="true" data-listmaxheight="340px" data-preload="auto" data-theme="#555"></div>
<p><strong>机器学习拥有庞大的知识体系，这里对机器学习的数据分析的整个思路和流程作最最简单的归纳。机器学习的步骤大致包括：<br>1）理解和清理数据<br>2）特征选择<br>3）算法建模<br>4）测试评估模型</strong><br><a id="more"></a></p>
<h1 id="机器学习数据分析极简思路"><a href="#机器学习数据分析极简思路" class="headerlink" title="机器学习数据分析极简思路"></a>机器学习数据分析极简思路</h1><h2 id="1）理解和清理数据"><a href="#1）理解和清理数据" class="headerlink" title="1）理解和清理数据"></a>1）理解和清理数据</h2><ul>
<li>理解数据<br>数据是机器学习大餐的原始食材，对数据分析起着至关重要的作用，理解原始数据的含义将有助于进一步分析。例如，甲基化图谱与年龄有着显著的相关性，而与性别关系不大，因此在数据分析中，对这两个特征（faeature）需要区别对待。更好的理解方式是直接可视化某些数据，例如对于经典的鸢尾花数据集，可以通过python seaborn绘图包可视化各个特征（feature）之间的关系；对于大数据，则可以进行降维分析（PCOA、tSNE），理解数据组成主成分贡献度。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#pip install seaborn</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> pyplot</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sb</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">%matplotlib inline</span><br><span class="line">data=pd.read_csv(<span class="string">'iris.csv'</span>)    <span class="comment">#pandas 读入数据</span></span><br><span class="line">data.head(<span class="number">3</span>)    <span class="comment">#查看数据</span></span><br><span class="line">data.describe() <span class="comment">#数据基本统计</span></span><br><span class="line">sb.pairplot(data.dropna(),hue=<span class="string">'Species'</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>鸢尾花数据组成<br><img src="/img/1.png" alt="32bc1a777af3001e5fc1dea42b93c0d1.png"><br>鸢尾花数据所有feature基本数理统计<br><img src="/img/2.png" alt="2b240766f89ac4edf021b4341265784a.png"><br>鸢尾花数据不同feature相互关系<br><img src="/img/3.png" alt="c6662ebd0cefd5735191807c454d879a.png"></p>
<ul>
<li>剔除异常值<br>清理数据的目的在于去除原始数据中的异常值和想办法处理缺失值，我们拿到手上的数据不可能尽善尽美，总有一些妖孽作祟，对于异常值我们应当剔除。举个栗子，假设在鸢尾花数据集中，有一个样本显示鸢尾花花瓣长度10m，其他诸如花瓣宽度、花萼长宽值都正常，可以脑补一下这是一朵什么样的花，那么这个样本显然应该剔除。</li>
<li>处理缺失值<br>缺失值在数据分析中很常见，总有一些样本观测值会因为这那的问题缺失，处理缺失值如果样本数量很大，而包含缺失值的样本又少，这个时候果断去掉这些样本，眼不见为净；如果因为样本有限或者缺失值太多，就要想办法补全缺失值（imputation）,常常利用逻辑回归建立模型，找出这些数据变化的规律，从而预测缺失值。如何合理推断和填回这些缺失值是一门大学问，哪种方法好，我也不敢妄言。</li>
</ul>
<h2 id="2）特征选择"><a href="#2）特征选择" class="headerlink" title="2）特征选择"></a>2）特征选择</h2><p>工业界广泛流传的一句话是：<strong>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已</strong>。由此可见，特征选择是机器学习的关键的关键。特征选择目的在于提取跟目标最为有效的信息，降低数据维度和计算成本，同时防止过拟合（overfitting，训练集特征用的太多太细，以致于在测试集中不适）。要知道，并不是特征越多，结果越好，没有严格意义上的特征累加效应，有时候好的几个特征胜于大量零碎的特征取得的效果。<br>在许多大数据挖掘竞赛中（国内的阿里天池和国外的kaggle平台），最复杂的过程莫过于特征工程建立阶段，大概占据了整个竞赛过程的70%的时间和精力，最终建立的模型的好坏大多也取决于特征工程建立的好坏。遗憾的是，特征工程不像模型建立的过程有着固定的套路，特征工程的建立凭借的更多的是经验，因此没有统一的方法。这里抛砖引玉介绍一些常见的办法，更为详细的内容请参考文后链接。<br><strong>a)特征过滤法</strong><br>比较简单，它按照特征的发散性或者相关性指标对各个特征进行评分，设定评分阈值或者待选择阈值的个数，选择合适特征。例如，我们可以简单的计算出每个feature的方差，方差越大说明这个feature在样本中变异大，即有区分性；而越小的（极端时方差为0），即表示在所有样本中一样，特征选择时则可不考虑这些特征。我们可以选择方差最大的前n个feature用于建模，这就是最为简单的方差筛选法。<br><strong>b)包装法</strong><br>根据目标函数，通常是预测效果评分，每次选择部分特征，或者排除部分特征。<br><strong>c)嵌入法</strong><br>则稍微复杂一点，它先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据权值系数从大到小来选择特征。类似于过滤法，但是它是通过机器学习训练来确定特征的优劣，而不是直接从特征的一些统计学指标来确定特征的优劣。<br><strong>踩雷说：特征选择之后，需要从原始数据矩阵提取相应的特征重构矩阵，那么训练集和测试集的特征经过你各种变换之后，应当保持一一对应，类别和顺序在矩阵中都应该一致。</strong><br>目前，已经有一些套路化的特征选择工具，例如python的FeatureSlector包，见链接。</p>
<h2 id="3）算法建模"><a href="#3）算法建模" class="headerlink" title="3）算法建模"></a>3）算法建模</h2><p>针对具体的问题，是分类问题？回归问题？还是其他？选择合适的模型，或者使用集成的算法模型。常见的算法模型包括：<br>对于回归问题：<br>a)线性回归（回归，LinearRegression）<br>b)岭回归（回归，Ridge）Ridge是线性回归加L2正则平方，以防止过拟合<br>c)拉索回归（Lasso），加入惩罚函数L1正则绝对值，防止过拟合<br>d)弹性网络回归（回归），同时使用L1和L2正则。<br>e)K近邻（回归和分类，KNeighborsRegressor）<br>f)决策树（回归和分类，DecisionTreeRegressor）<br>g)支持向量机（回归和分类，SVR）</p>
<p>对于分类问题：<br>a)支持向量机（回归和分类，SVC）<br>b决策树（回归与分类,DecisionTreeClassifier）<br>c)逻辑回归（分类,LogisticRegression)<br>d)LDA线性判别分析（分类,LinearDiscriminantAnalysis)<br>e)K近邻（分类,KNeighborsClassifier)<br>值得一提的是无论是分类还是回归问题，基于决策树和SVM的算法都有比较好的表现。</p>
<h2 id="4）测试评估模型"><a href="#4）测试评估模型" class="headerlink" title="4）测试评估模型"></a>4）测试评估模型</h2><p>测试评估模型的目的在于，解决模型的欠拟合（under-fitting）和过拟合（over-fitting）问题，通过即时的反馈不断调整模型、优化模型，使得模型更加稳健。<br>实际上，测试评估模型应该在你建模之前就考虑，例如是否需要设置纯粹的外部数据验证集，若没有这样的数据，你怎样划分数据进行建模预测？<br>在实际训练中，模型通常对训练数据好，但是对训练数据之外的数据拟合程度差。用于评价模型的泛化能力（即模型普适性）。交叉验证的基本思想是把在某种意义下将原始数据进行分组,一部分做为训练集(train set),另一部分做为验证集(validation set or test set),首先用训练集对模型进行训练,再利用验证集来测试模型的泛化误差。另外，现实中数据总是有限的，为了对数据形成重用，比较常用的是k-fold交叉验证法。测试评估模型的时候，常常结合AUC曲线判断模型好坏。</p>
<h1 id="sklearn-算法小试"><a href="#sklearn-算法小试" class="headerlink" title="sklearn 算法小试"></a>sklearn 算法小试</h1><h2 id="实现目的"><a href="#实现目的" class="headerlink" title="实现目的"></a>实现目的</h2><p>sklearn是python中一个强大的机器学习模块,拥有众多的机器学习算法和功能。这里，通过sklearn的datasets构建一个数据集，并用4种常用算法：逻辑回归（LogisticRegression）、支持向量机（SVM）、决策树（DecisionTree）和集成算法（VotingClassifier）对训练集建模，然后对测试集预测，最终通过得分看一下4种算法的差异。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>1）构建本次使用的数据集<br>2）将数据拆分成训练集和测试集<br>3）用4种算法分别建模、预测</p>
<h2 id="代码环境"><a href="#代码环境" class="headerlink" title="代码环境"></a>代码环境</h2><p>python版本：python3<br>1）如果不想被python各种安装包困扰，推荐Jupyter在线python，<a href="https://jupyter.org/" target="_blank" rel="noopener">Jupyter官网</a>，点击”Try Jupyter with Python”，点击“+”号即可。安装包的时候直接pip install packages_name,例如pip install sklearn,点击“Run”，提示“Successfully installed sklearn-0.0”即安装完成。<br><img src="/img/4.png" alt="a3e70c182d26dd77208c02cab6571af5.png"><br>2）Pycharm，专业、高效、强大的python开发端。</p>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="comment">#built-in datasets</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#make_moons,generated datasets</span></span><br><span class="line">X,y = datasets.make_moons(n_samples=<span class="number">500</span>,noise=<span class="number">0.3</span>,random_state=<span class="number">42</span>)</span><br><span class="line">plt.scatter(X[y==<span class="number">0</span>,<span class="number">0</span>],X[y==<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">plt.scatter(X[y==<span class="number">1</span>,<span class="number">0</span>],X[y==<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">plt.show()  <span class="comment">#plot for datasets</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#split datasets for train and test part</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#1.logistic regression model</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">log_clf=LogisticRegression() <span class="comment">#create LR classifer</span></span><br><span class="line">log_clf.fit(X_train,y_train) <span class="comment">#train and fit the model</span></span><br><span class="line">log_score=log_clf.score(X_test,y_test) <span class="comment">#test the model</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2.svm model</span></span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">svm_clf=SVC()</span><br><span class="line">svm_clf.fit(X_train,y_train)</span><br><span class="line">svm_score=svm_clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.decision tree model</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt_clf=DecisionTreeClassifier()</span><br><span class="line">dt_clf.fit(X_train,y_train)</span><br><span class="line">dt_score=dt_clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.ensemble method</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> VotingClassifier</span><br><span class="line">voting_clf=VotingClassifier(estimators=</span><br><span class="line">                            [(<span class="string">'log_clf'</span>,LogisticRegression()),</span><br><span class="line">                             (<span class="string">'svm_clf'</span>,SVC()),</span><br><span class="line">                             (<span class="string">'dt_clf'</span>,DecisionTreeClassifier())</span><br><span class="line">                             ],voting=<span class="string">"hard"</span>)</span><br><span class="line">voting_clf.fit(X_train,y_train)</span><br><span class="line">voting_score=voting_clf.score(X_test,y_test)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"log score:%s"</span>%log_score)</span><br><span class="line">print(<span class="string">"svm score:%s"</span>%svm_score)</span><br><span class="line">print(<span class="string">"dt score:%s"</span>%dt_score)</span><br><span class="line">print(<span class="string">"voting score:%s"</span>%voting_score)</span><br></pre></td></tr></table></figure>
<p>构建数据集：<br><img src="/img/5.png" alt="c6e3145820fe446499bfe5166f85b29e.png"><br>4种算法预测结果：<br><img src="/img/6.png" alt="a59578cf44dee88a46ef0bcceabf1b2b.png"><br>可以看到，单一算法SVM比较好，集成算法较单一的算法还是有一定的提高。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.zhihu.com/question/28641663?utm_source=wechat_search&amp;utm_medium=organic" target="_blank" rel="noopener">机器学习中，有哪些特征选择的工程方法？</a><br><a href="https://mp.weixin.qq.com/s?__biz=Mzg5ODAzMTkyMg==&amp;mid=2247485387&amp;idx=1&amp;sn=d22618f98adae3c9038184b9c4991ea2&amp;chksm=c0698f96f71e06807bbb3c667d50aa87899aa8d7b48bab51be33206390a03cb2e28d3ddb27b4&amp;mpshare=1&amp;scene=24&amp;srcid=0327GWk8nsWdgLT2kYwpeazY#rd" target="_blank" rel="noopener">FeatureSlector:一个可以进行机器学习特征选择的python工具</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzI2MjE3OTA1MA==&amp;mid=2247484860&amp;idx=1&amp;sn=7ea3597474f5ceaf443f10d63a8217ee&amp;chksm=ea4e5439dd39dd2f2f0cd95eca909e2ab255fc5dc6e033e9b2d265bf2124751f32e96279188d&amp;scene=7#rd" target="_blank" rel="noopener">机器学习中的交叉验证</a></p>

        <div>
            <ul class="tags-category-list"><li class="tags-category-list-item"><a class="tags-category-list-link" href="/tags/algorithm/">algorithm</a></li></ul>
        </div>
        <div class="bottom-line"></div>
        
    <nav id="article-nav">
        
            <a href="/2019/03/31/western-blot/" id="article-nav-newer" class="article-nav-link-wrap">
        <span class="article-nav-title">
            
                师兄又在胡扯了-Western Blot
            
        </span>
                <strong class="article-nav-caption">&gt;</strong>
            </a>
        
        
            <a href="/2019/03/20/UBGBs/" id="article-nav-older" class="article-nav-link-wrap">
                <strong class="article-nav-caption">&lt;</strong>
                <span class="article-nav-title">
                    
                        UBGBs
                </span>
                
            </a>
        
    </nav>


        
            <div id="stageComment" class="comment" style="margin-top: 27px;"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
  var notify = 'false' == true ? true : false;
  var verify = 'false' == true ? true : false;
  window.onload = function() {
    new Valine({
      el: '#stageComment',
      notify: notify,
      verify: verify,
      app_id: "aok3pCDe5ao2IIhmO7Cwjmgi-gzGzoHsz",
      app_key: "QT8zl1KLRblAYwCsuCcj6JAz",
      placeholder: "小姐姐、小哥哥，快来夸我啊!",
      avatar:"mm"
    });
  }
</script>

        
    </article>
    <div id="toc">
        
            <h2>Table of Contents</h2>
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#机器学习数据分析极简思路"><span class="toc-number">1.</span> <span class="toc-text">机器学习数据分析极简思路</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1）理解和清理数据"><span class="toc-number">1.1.</span> <span class="toc-text">1）理解和清理数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2）特征选择"><span class="toc-number">1.2.</span> <span class="toc-text">2）特征选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3）算法建模"><span class="toc-number">1.3.</span> <span class="toc-text">3）算法建模</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4）测试评估模型"><span class="toc-number">1.4.</span> <span class="toc-text">4）测试评估模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sklearn-算法小试"><span class="toc-number">2.</span> <span class="toc-text">sklearn 算法小试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#实现目的"><span class="toc-number">2.1.</span> <span class="toc-text">实现目的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#步骤"><span class="toc-number">2.2.</span> <span class="toc-text">步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代码环境"><span class="toc-number">2.3.</span> <span class="toc-text">代码环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#源码"><span class="toc-number">2.4.</span> <span class="toc-text">源码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#参考"><span class="toc-number">3.</span> <span class="toc-text">参考</span></a></li></ol>
        
    </div>
</div>

    </div>
</div>
<footer id="footer">
    <div id="copyright">&copy; Uranusyt  2019</div>
    <div id="theme">
        Powered by <a href="http://hexo.io">Hexo</a>. Theme by <a href="https://github.com/markyong/hexo-theme-stage">Stage</a>
    </div>
</footer>
<script src="/lib/js/waterrippleeffect.min.js"></script>
<script src="/js/header-bg.main.js"></script>

    <script src="/lib/js/smooth-scroll.min.js"></script>
    <script src="/js/toc.main.js"></script>
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_uv"> 
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>
    <span id="busuanzi_container_page_pv">
   本文总阅读量<span id="busuanzi_value_page_pv"></span>次
</span>

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>
